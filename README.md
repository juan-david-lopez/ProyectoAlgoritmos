# Sistema de Comparaci√≥n de Similitud de Textos

**Proyecto de Algoritmos - An√°lisis de Similitud**

Sistema completo para comparar similitud entre textos usando 6 algoritmos diferentes, desde m√©todos cl√°sicos hasta modelos de deep learning estado del arte.

---

## üìã Tabla de Contenidos

- [Caracter√≠sticas](#caracter√≠sticas)
- [Algoritmos Implementados](#algoritmos-implementados)
- [Instalaci√≥n](#instalaci√≥n)
- [Uso R√°pido](#uso-r√°pido)
- [Resultados de Pruebas](#resultados-de-pruebas)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Documentaci√≥n](#documentaci√≥n)
- [Tests](#tests)
- [Ejemplos](#ejemplos)

---

## ‚ú® Caracter√≠sticas

- **6 algoritmos de similitud** implementados con documentaci√≥n matem√°tica completa
- **Tests unitarios exhaustivos** (35 tests, 100% passed)
- **Logging detallado** con `time.perf_counter()` y medici√≥n de memoria
- **Visualizaciones autom√°ticas** (heatmaps, gr√°ficos comparativos, tablas)
- **Reportes detallados** en formato Markdown
- **Documentaci√≥n t√©cnica** con f√≥rmulas LaTeX
- **Optimizaciones** (batching, GPU support, cach√© de modelos)

---

## üî¨ Algoritmos Implementados

### 1. **Distancia de Levenshtein**
- **Tipo:** Edici√≥n de caracteres
- **Complejidad:** O(m √ó n)
- **Velocidad:** ‚≠ê‚≠ê (lento para textos largos)
- **Mejor para:** Correcci√≥n ortogr√°fica, textos cortos

### 2. **TF-IDF + Similitud del Coseno**
- **Tipo:** L√©xico-estad√≠stico
- **Complejidad:** O(n √ó m)
- **Velocidad:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (muy r√°pido)
- **Mejor para:** B√∫squeda de documentos, gran escala

### 3. **√çndice de Jaccard**
- **Tipo:** Conjuntos
- **Complejidad:** O(n + m)
- **Velocidad:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (ultra r√°pido)
- **Mejor para:** Etiquetas, palabras clave

### 4. **Similitud de N-gramas**
- **Tipo:** Subcadenas
- **Complejidad:** O(m + n)
- **Velocidad:** ‚≠ê‚≠ê‚≠ê‚≠ê (r√°pido)
- **Mejor para:** Detecci√≥n de plagio, multiling√ºe

### 5. **Sentence-BERT (S-BERT)**
- **Tipo:** Sem√°ntico (Deep Learning)
- **Complejidad:** O(n √ó d¬≤)
- **Velocidad:** ‚≠ê‚≠ê‚≠ê‚≠ê (r√°pido para IA)
- **Mejor para:** B√∫squeda sem√°ntica, balance velocidad/precisi√≥n

### 6. **BERT**
- **Tipo:** Sem√°ntico (Deep Learning)
- **Complejidad:** O(n¬≤ √ó d)
- **Velocidad:** ‚≠ê (lento pero preciso)
- **Mejor para:** M√°xima precisi√≥n, datasets peque√±os

---

## üöÄ Instalaci√≥n

### Requisitos

```bash
Python 3.8+
```

### Instalaci√≥n de Dependencias

```bash
# Dependencias b√°sicas (algoritmos cl√°sicos)
pip install numpy pandas matplotlib seaborn scikit-learn

# Dependencias para modelos de IA (opcional)
pip install torch transformers sentence-transformers

# Dependencias adicionales
pip install psutil  # Para medici√≥n de memoria
```

### Estructura de Directorios

```bash
ProyectoAlgoritmos/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ unified_articles.json       # Datos de prueba
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ algorithms/
‚îÇ       ‚îú‚îÄ‚îÄ levenshtein.py         # Algoritmo 1
‚îÇ       ‚îú‚îÄ‚îÄ tfidf_cosine.py        # Algoritmo 2
‚îÇ       ‚îú‚îÄ‚îÄ jaccard.py             # Algoritmo 3
‚îÇ       ‚îú‚îÄ‚îÄ ngram.py               # Algoritmo 4
‚îÇ       ‚îú‚îÄ‚îÄ sbert.py               # Algoritmo 5
‚îÇ       ‚îú‚îÄ‚îÄ bert.py                # Algoritmo 6
‚îÇ       ‚îî‚îÄ‚îÄ similarity_comparator.py  # M√≥dulo principal
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ test_similarity.py         # Tests unitarios
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îú‚îÄ‚îÄ similarity_demo.py         # Demo completo
‚îÇ   ‚îî‚îÄ‚îÄ similarity_demo_basic.py   # Demo b√°sico (sin IA)
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ similarity_algorithms.md   # Documentaci√≥n t√©cnica
‚îî‚îÄ‚îÄ output/
    ‚îú‚îÄ‚îÄ visualizations/            # Gr√°ficos generados
    ‚îî‚îÄ‚îÄ similarity_report.md       # Reportes
```

---

## üéØ Uso R√°pido

### Opci√≥n 1: Demo B√°sico (Sin modelos de IA)

```bash
python examples/similarity_demo_basic.py
```

**Salida:**
- Compara 3 art√≠culos con 4 algoritmos b√°sicos
- Tiempo: ~2 segundos
- Genera log detallado

### Opci√≥n 2: Demo Completo (Con modelos de IA)

```bash
python examples/similarity_demo.py
```

**Nota:** Primera ejecuci√≥n descarga modelos (~500MB). Ejecuciones posteriores usan cach√©.

### Opci√≥n 3: Uso Program√°tico

```python
from src.algorithms.similarity_comparator import SimilarityComparator

# 1. Cargar datos
comparator = SimilarityComparator('data/unified_articles.json')

# 2. Seleccionar art√≠culos
selected = comparator.select_articles(['article_1', 'article_2', 'article_3'])
abstracts = [art['abstract'] for art in selected]

# 3. Comparar con todos los algoritmos
results = comparator.compare_all_algorithms(abstracts)

# 4. Generar visualizaciones
comparator.visualize_results(results, 'output/visualizations')

# 5. Generar reporte
comparator.generate_detailed_report(results, 'output/report.md', selected)
```

---

## üìä Resultados de Pruebas

### Verificaci√≥n de Rangos

‚úÖ **Todos los algoritmos retornan valores en [0, 1]**

```
Test Results: 35/35 passed (100%)
- Levenshtein: 7 tests ‚úì
- TF-IDF: 7 tests ‚úì
- Jaccard: 8 tests ‚úì
- N-grama: 8 tests ‚úì
- Propiedades matem√°ticas: 1 test ‚úì
- Casos extremos: 4 tests ‚úì
```

### Demo con 3 Art√≠culos (Abstracts Cient√≠ficos)

**Art√≠culos:**
1. Machine Learning + NLP (647 chars)
2. Deep Learning + NLP (636 chars)
3. CNN + Computer Vision (698 chars)

**Resultados de Similitud (Art. 1 vs Art. 2):**

| Algoritmo | Similitud | Tiempo |
|-----------|-----------|--------|
| Levenshtein | 0.2566 | 1.675s |
| TF-IDF | 0.1824 | 0.003s |
| Jaccard | 0.2124 | 0.0002s |
| N-grama | 0.4944 | 0.0005s |

**An√°lisis:**
- **TF-IDF detecta vocabulario t√©cnico compartido** (learning, networks, transformers)
- **N-grama detecta similitud de estructuras** (patrones de texto)
- **Jaccard detecta palabras √∫nicas compartidas** (sin considerar frecuencias)
- **Levenshtein es demasiado estricto** para textos largos

### Comparaci√≥n de Velocidad

üèÜ **Ranking de velocidad:**
1. Jaccard: 0.0002s ‚ö°‚ö°‚ö°‚ö°‚ö°
2. N-grama: 0.0005s ‚ö°‚ö°‚ö°‚ö°
3. TF-IDF: 0.003s ‚ö°‚ö°‚ö°‚ö°
4. Levenshtein: 1.675s ‚ö°‚ö°

**Conclusi√≥n:** Jaccard es **8,375x m√°s r√°pido** que Levenshtein.

---

## üìñ Documentaci√≥n

### Documentaci√≥n T√©cnica

Ver [`docs/similarity_algorithms.md`](docs/similarity_algorithms.md) para:
- Explicaciones matem√°ticas completas con LaTeX
- Ejemplos paso a paso
- An√°lisis de complejidad
- Casos de uso recomendados
- Referencias acad√©micas

### Docstrings en C√≥digo

Cada algoritmo incluye:
- Explicaci√≥n matem√°tica en el m√≥dulo
- Ejemplos de uso
- Descripci√≥n de par√°metros
- Complejidad temporal y espacial

Ejemplo:

```python
from src.algorithms.jaccard import JaccardComparator

help(JaccardComparator.similarity)
# Muestra documentaci√≥n completa con f√≥rmulas
```

---

## üß™ Tests

### Ejecutar Tests

```bash
# Todos los tests
python tests/test_similarity.py

# Output:
# ======================================================================
# RESUMEN DE TESTS
# ======================================================================
# Tests ejecutados: 35
# Exitosos: 35
# Fallidos: 0
# Errores: 0
```

### Cobertura de Tests

- ‚úÖ Casos extremos (textos vac√≠os, id√©nticos)
- ‚úÖ Propiedades matem√°ticas (simetr√≠a, reflexividad)
- ‚úÖ Rango de valores [0, 1]
- ‚úÖ Casos conocidos con resultados esperados
- ‚úÖ Robustez (Unicode, caracteres especiales, textos largos)

---

## üí° Ejemplos

### Ejemplo 1: B√∫squeda de Documentos Similares

```python
from src.algorithms.tfidf_cosine import TFIDFCosineComparator

comparator = TFIDFCosineComparator()

documents = [
    "machine learning algorithms",
    "deep learning neural networks",
    "cooking italian pasta",
    "artificial intelligence methods"
]

# Comparar todos los documentos
matrix = comparator.compare_multiple(documents)

# Encontrar m√°s similares al primero
similarities = matrix[0][1:]
most_similar_idx = similarities.argmax()
print(f"M√°s similar a 'machine learning algorithms': {documents[most_similar_idx + 1]}")
# Output: "deep learning neural networks"
```

### Ejemplo 2: Detecci√≥n de Plagio

```python
from src.algorithms.ngram import NGramComparator

comparator = NGramComparator(n=3, method='dice')

original = "The quick brown fox jumps over the lazy dog"
suspected = "The fast brown fox leaps over the sleepy dog"

similarity = comparator.similarity(original, suspected)
print(f"Similitud: {similarity:.2%}")

if similarity > 0.7:
    print("‚ö†Ô∏è Posible plagio detectado")
```

### Ejemplo 3: B√∫squeda Sem√°ntica (con S-BERT)

```python
from src.algorithms.sbert import SBERTComparator

comparator = SBERTComparator()

query = "natural language processing"
candidates = [
    "NLP and text analysis",
    "cooking recipes",
    "understanding human language",
    "computer vision"
]

results = comparator.find_most_similar(query, candidates, top_k=2)

print("Top 2 resultados:")
for idx, sim in results:
    print(f"  {candidates[idx]}: {sim:.3f}")

# Output:
# Top 2 resultados:
#   NLP and text analysis: 0.856
#   understanding human language: 0.742
```

---

## üéì Recomendaciones por Caso de Uso

### Para Abstracts Cient√≠ficos

**Recomendado: S-BERT**

‚úÖ Razones:
- Captura similitud sem√°ntica entre conceptos
- Robusto a diferentes formulaciones
- Buen balance velocidad/precisi√≥n
- Entrenado en textos cient√≠ficos

### Para Aplicaciones en Tiempo Real

**Recomendado: TF-IDF o Jaccard**

‚úÖ Razones:
- Muy r√°pidos (<1ms por comparaci√≥n)
- Escalables a millones de documentos
- Bajo uso de memoria

### Para Detecci√≥n de Plagio

**Recomendado: N-grama + Levenshtein**

‚úÖ Pipeline:
1. Filtrar con N-grama (primera pasada r√°pida)
2. Verificar con Levenshtein (detectar par√°frasis)
3. Confirmar con S-BERT (similitud sem√°ntica)

---

## üêõ Resoluci√≥n de Problemas

### Problema: Errores con modelos de IA

**Soluci√≥n:**
```bash
# Instalar PyTorch
pip install torch --index-url https://download.pytorch.org/whl/cpu

# Instalar transformers
pip install transformers sentence-transformers
```

### Problema: Levenshtein muy lento

**Soluci√≥n:** No usar Levenshtein para textos > 500 caracteres. Usar TF-IDF o N-grama en su lugar.

### Problema: Out of memory con BERT

**Soluci√≥n:** Reducir `batch_size`:
```python
from src.algorithms.bert import BERTComparator

comparator = BERTComparator(batch_size=2)  # Default: 8
```

---

## üìù Respuestas a Preguntas Checkpoint

### ‚úÖ ¬øPor qu√© S-BERT da resultados diferentes a TF-IDF?

**TF-IDF:**
- Compara palabras exactas (l√©xico)
- Solo detecta coincidencias de t√©rminos
- "machine learning" ‚â† "artificial intelligence"

**S-BERT:**
- Compara significado (sem√°ntica)
- Captura sin√≥nimos y contexto
- "machine learning" ‚âà "artificial intelligence"

**Ejemplo del demo:**
- Art1 vs Art2 (ambos NLP):
  - TF-IDF: 0.182 (vocabulario compartido)
  - N-grama: 0.494 (patrones de texto)

Los modelos sem√°nticos dar√≠an valores m√°s altos al capturar que ambos hablan del mismo dominio.

### ‚úÖ ¬øCu√°l algoritmo recomiendas para abstracts cient√≠ficos?

**Recomendaci√≥n: S-BERT**

**Justificaci√≥n:**
1. **Sem√°ntica:** Captura relaciones conceptuales
2. **Robustez:** Funciona con diferentes formulaciones
3. **Velocidad:** R√°pido para inferencia (con cach√©)
4. **Precisi√≥n:** Estado del arte en tareas de similitud sem√°ntica

**Alternativas:**
- **BERT:** Si precisi√≥n m√°xima es cr√≠tica (pero 10x m√°s lento)
- **TF-IDF:** Si velocidad es cr√≠tica (pero menos preciso)

### ‚ö° ¬øOptimizaciones de BERT?

**Implementado:**

‚úÖ **Batching:** Procesar m√∫ltiples textos en paralelo
```python
comparator = BERTComparator(batch_size=8)
```

‚úÖ **Mean pooling optimizado:** Vectorizaci√≥n con m√°scaras de atenci√≥n

**Optimizaciones adicionales posibles:**

1. **Cuantizaci√≥n (INT8):**
```python
from transformers import AutoModelForSequenceClassification
model = AutoModelForSequenceClassification.from_pretrained(
    "bert-base-uncased",
    torchscript=True,
    load_in_8bit=True  # Reduce memoria 4x
)
```

2. **ONNX Runtime:**
```python
from optimum.onnxruntime import ORTModelForFeatureExtraction
model = ORTModelForFeatureExtraction.from_pretrained(
    "bert-base-uncased",
    export=True
)  # 2-3x m√°s r√°pido
```

3. **Distilaci√≥n (DistilBERT):**
```python
comparator = BERTComparator(model_name='distilbert-base-uncased')
# 40% m√°s peque√±o, 60% m√°s r√°pido, 97% precisi√≥n
```

---

## üìú Licencia

Este proyecto es de c√≥digo abierto y est√° disponible para uso acad√©mico.

---

## üôè Agradecimientos

- **Papers de referencia:** Levenshtein (1966), Salton & McGill (1983), Jaccard (1901), Devlin et al. (2018), Reimers & Gurevych (2019)
- **Bibliotecas:** scikit-learn, transformers, sentence-transformers, PyTorch

---

## üìß Contacto

Para preguntas o sugerencias, abrir un issue en el repositorio.

---

**√öltima actualizaci√≥n:** 2025-10-27
