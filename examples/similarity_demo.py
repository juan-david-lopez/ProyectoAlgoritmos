"""
Script de demostraci√≥n completo del sistema de comparaci√≥n de similitud.

Este script demuestra el flujo completo:
1. Cargar datos unificados
2. Seleccionar 3-5 art√≠culos de ejemplo
3. Comparar con todos los 6 algoritmos
4. Generar visualizaciones
5. Crear reporte detallado

Autor: Sistema de An√°lisis de Similitud
Fecha: 2025-10-27
"""

import sys
import time
import logging
from pathlib import Path

# Configurar path para importar m√≥dulos
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.algorithms.similarity_comparator import SimilarityComparator


# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('similarity_demo.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def main():
    """
    Funci√≥n principal que ejecuta la demostraci√≥n completa.
    """
    logger.info("=" * 80)
    logger.info("INICIANDO DEMOSTRACI√ìN DE COMPARACI√ìN DE SIMILITUD")
    logger.info("=" * 80)

    # Medir tiempo total de ejecuci√≥n
    start_time_total = time.perf_counter()

    try:
        # ========================================================================
        # PASO 1: CARGAR DATOS
        # ========================================================================
        logger.info("\n" + "=" * 80)
        logger.info("PASO 1: CARGANDO DATOS")
        logger.info("=" * 80)

        data_path = 'data/unified_articles.json'
        logger.info(f"Ruta de datos: {data_path}")

        start_time = time.perf_counter()
        comparator = SimilarityComparator(data_path)
        elapsed = time.perf_counter() - start_time

        logger.info(f"‚úì Datos cargados exitosamente en {elapsed:.3f} segundos")

        # ========================================================================
        # PASO 2: SELECCIONAR ART√çCULOS
        # ========================================================================
        logger.info("\n" + "=" * 80)
        logger.info("PASO 2: SELECCIONANDO ART√çCULOS DE EJEMPLO")
        logger.info("=" * 80)

        # Opci√≥n 1: Seleccionar por IDs espec√≠ficos (si conoces los IDs)
        # article_ids = ['article_1', 'article_2', 'article_3']

        # Opci√≥n 2: Seleccionar los primeros N art√≠culos
        num_articles = 3
        article_ids = [article['id'] for article in comparator.unified_data[:num_articles]]

        logger.info(f"Art√≠culos seleccionados: {article_ids}")

        start_time = time.perf_counter()
        selected_articles = comparator.select_articles(article_ids)
        elapsed = time.perf_counter() - start_time

        logger.info(f"‚úì {len(selected_articles)} art√≠culos seleccionados en {elapsed:.3f} segundos")

        # Mostrar informaci√≥n de art√≠culos seleccionados
        for idx, article in enumerate(selected_articles, 1):
            logger.info(f"\n  Art√≠culo {idx}:")
            logger.info(f"    ID: {article['id']}")
            logger.info(f"    T√≠tulo: {article['title'][:80]}...")
            logger.info(f"    Abstract: {article['abstract'][:150]}...")
            logger.info(f"    Longitud: {len(article['abstract'])} caracteres")

        # Extraer abstracts
        abstracts = [article['abstract'] for article in selected_articles]

        # ========================================================================
        # PASO 3: COMPARAR CON TODOS LOS ALGORITMOS
        # ========================================================================
        logger.info("\n" + "=" * 80)
        logger.info("PASO 3: COMPARANDO CON TODOS LOS ALGORITMOS")
        logger.info("=" * 80)

        start_time = time.perf_counter()
        results = comparator.compare_all_algorithms(abstracts)
        elapsed = time.perf_counter() - start_time

        logger.info(f"\n‚úì Comparaci√≥n completada en {elapsed:.3f} segundos")

        # Mostrar resumen de resultados
        logger.info("\n" + "-" * 80)
        logger.info("RESUMEN DE RESULTADOS:")
        logger.info("-" * 80)

        algorithms = ['levenshtein', 'tfidf_cosine', 'jaccard', 'ngram', 'sbert', 'bert']

        for algo_name in algorithms:
            exec_time = results['execution_times'].get(algo_name)
            mem_usage = results['memory_usage'].get(algo_name)
            sim_matrix = results['similarities'].get(algo_name)

            if exec_time is not None and sim_matrix is not None:
                # Calcular estad√≠sticas
                import numpy as np
                mask = ~np.eye(sim_matrix.shape[0], dtype=bool)
                sim_values = sim_matrix[mask]

                logger.info(f"\n{algo_name.upper()}:")
                logger.info(f"  Tiempo: {exec_time:.3f}s")
                logger.info(f"  Memoria: {mem_usage:.2f} MB")
                logger.info(f"  Similitud media: {np.mean(sim_values):.3f}")
                logger.info(f"  Similitud m√°xima: {np.max(sim_values):.3f}")
                logger.info(f"  Similitud m√≠nima: {np.min(sim_values):.3f}")

                # Verificar que los valores est√©n en [0, 1]
                if np.min(sim_matrix) < 0 or np.max(sim_matrix) > 1:
                    logger.warning(f"  ‚ö†Ô∏è ADVERTENCIA: Valores fuera del rango [0,1]!")
                else:
                    logger.info(f"  ‚úì Valores en rango correcto [0,1]")

        # ========================================================================
        # PASO 4: GENERAR VISUALIZACIONES
        # ========================================================================
        logger.info("\n" + "=" * 80)
        logger.info("PASO 4: GENERANDO VISUALIZACIONES")
        logger.info("=" * 80)

        output_dir = 'output/visualizations'
        logger.info(f"Directorio de salida: {output_dir}")

        start_time = time.perf_counter()
        comparator.visualize_results(results, output_dir)
        elapsed = time.perf_counter() - start_time

        logger.info(f"‚úì Visualizaciones generadas en {elapsed:.3f} segundos")
        logger.info(f"  - Heatmaps de similitud: {output_dir}/similarity_heatmaps.png")
        logger.info(f"  - Tiempos de ejecuci√≥n: {output_dir}/execution_times.png")
        logger.info(f"  - Uso de memoria: {output_dir}/memory_usage.png")
        logger.info(f"  - Tabla comparativa: {output_dir}/comparison_table.png")

        # ========================================================================
        # PASO 5: CREAR REPORTE DETALLADO
        # ========================================================================
        logger.info("\n" + "=" * 80)
        logger.info("PASO 5: GENERANDO REPORTE DETALLADO")
        logger.info("=" * 80)

        report_path = 'output/similarity_report.md'
        logger.info(f"Ruta del reporte: {report_path}")

        start_time = time.perf_counter()
        comparator.generate_detailed_report(results, report_path, selected_articles)
        elapsed = time.perf_counter() - start_time

        logger.info(f"‚úì Reporte generado en {elapsed:.3f} segundos")

        # ========================================================================
        # RESUMEN FINAL
        # ========================================================================
        elapsed_total = time.perf_counter() - start_time_total

        logger.info("\n" + "=" * 80)
        logger.info("DEMOSTRACI√ìN COMPLETADA EXITOSAMENTE")
        logger.info("=" * 80)
        logger.info(f"Tiempo total de ejecuci√≥n: {elapsed_total:.3f} segundos")
        logger.info(f"Art√≠culos analizados: {len(selected_articles)}")
        logger.info(f"Algoritmos ejecutados: {len([a for a in algorithms if results['execution_times'].get(a) is not None])}")
        logger.info(f"\nResultados guardados en:")
        logger.info(f"  - Visualizaciones: {output_dir}/")
        logger.info(f"  - Reporte: {report_path}")
        logger.info(f"  - Log: similarity_demo.log")

        # ========================================================================
        # AN√ÅLISIS COMPARATIVO
        # ========================================================================
        logger.info("\n" + "=" * 80)
        logger.info("AN√ÅLISIS COMPARATIVO")
        logger.info("=" * 80)

        # Algoritmo m√°s r√°pido
        fastest = min(
            [(name, time) for name, time in results['execution_times'].items() if time is not None],
            key=lambda x: x[1]
        )
        logger.info(f"\nüèÜ Algoritmo m√°s r√°pido: {fastest[0].upper()} ({fastest[1]:.3f}s)")

        # Algoritmo con menor memoria
        lowest_mem = min(
            [(name, mem) for name, mem in results['memory_usage'].items() if mem is not None],
            key=lambda x: x[1]
        )
        logger.info(f"üíæ Menor uso de memoria: {lowest_mem[0].upper()} ({lowest_mem[1]:.2f} MB)")

        # Algoritmo m√°s lento
        slowest = max(
            [(name, time) for name, time in results['execution_times'].items() if time is not None],
            key=lambda x: x[1]
        )
        logger.info(f"üêå Algoritmo m√°s lento: {slowest[0].upper()} ({slowest[1]:.3f}s)")

        # Comparar S-BERT vs TF-IDF
        logger.info("\n" + "-" * 80)
        logger.info("COMPARACI√ìN: S-BERT vs TF-IDF")
        logger.info("-" * 80)

        import numpy as np

        sbert_matrix = results['similarities'].get('sbert')
        tfidf_matrix = results['similarities'].get('tfidf_cosine')

        if sbert_matrix is not None and tfidf_matrix is not None:
            mask = ~np.eye(sbert_matrix.shape[0], dtype=bool)

            sbert_avg = np.mean(sbert_matrix[mask])
            tfidf_avg = np.mean(tfidf_matrix[mask])

            logger.info(f"S-BERT - Similitud promedio: {sbert_avg:.3f}")
            logger.info(f"TF-IDF - Similitud promedio: {tfidf_avg:.3f}")
            logger.info(f"Diferencia: {abs(sbert_avg - tfidf_avg):.3f}")

            logger.info("\nüìä ¬øPor qu√© S-BERT da resultados diferentes?")
            logger.info("  ‚Ä¢ TF-IDF: Compara palabras exactas (l√©xico)")
            logger.info("  ‚Ä¢ S-BERT: Compara significado (sem√°ntica)")
            logger.info("  ‚Ä¢ S-BERT captura sin√≥nimos y contexto")
            logger.info("  ‚Ä¢ TF-IDF solo coincidencias de t√©rminos")

            if sbert_avg > tfidf_avg:
                logger.info("\n  ‚Üí S-BERT detecta m√°s similitud sem√°ntica")
                logger.info("    (los textos hablan de temas relacionados)")
            else:
                logger.info("\n  ‚Üí TF-IDF detecta m√°s coincidencias l√©xicas")
                logger.info("    (los textos usan palabras similares)")

        # ========================================================================
        # RECOMENDACIONES
        # ========================================================================
        logger.info("\n" + "=" * 80)
        logger.info("RECOMENDACIONES PARA ABSTRACTS CIENT√çFICOS")
        logger.info("=" * 80)

        logger.info("\nüéØ Recomendaci√≥n principal: S-BERT")
        logger.info("\nRazones:")
        logger.info("  1. Captura similitud sem√°ntica (conceptos relacionados)")
        logger.info("  2. Robusto a diferentes formulaciones del mismo concepto")
        logger.info("  3. Buen balance velocidad/precisi√≥n")
        logger.info("  4. Entrenado en textos cient√≠ficos")

        logger.info("\nüìå Alternativas seg√∫n contexto:")
        logger.info("  ‚Ä¢ Tiempo real / Alto volumen ‚Üí TF-IDF")
        logger.info("  ‚Ä¢ M√°xima precisi√≥n / Dataset peque√±o ‚Üí BERT")
        logger.info("  ‚Ä¢ Recursos limitados ‚Üí Jaccard o N-gram")
        logger.info("  ‚Ä¢ Detecci√≥n de plagio ‚Üí Levenshtein + N-gram")

        logger.info("\n" + "=" * 80)

    except FileNotFoundError as e:
        logger.error(f"‚ùå Error: Archivo no encontrado - {e}")
        logger.error("Aseg√∫rate de que 'data/unified_articles.json' existe")
        sys.exit(1)

    except Exception as e:
        logger.error(f"‚ùå Error inesperado: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()
