"""
Script para unificar los art√≠culos extra√≠dos de las 3 bases de datos
"""
import json
import os
from datetime import datetime

# Archivos m√°s recientes de cada base de datos
archivos = [
    "data/raw/uniquindio/uniquindio_acm_digital_library_20251030_131341.json",
    "data/raw/uniquindio/uniquindio_sciencedirect_20251030_131543.json",
    "data/raw/uniquindio/uniquindio_springer_20251030_131705.json"
]

print("\n" + "="*80)
print("üìö UNIFICACI√ìN DE ART√çCULOS")
print("="*80 + "\n")

todos_articulos = []
estadisticas = {}

for archivo in archivos:
    if os.path.exists(archivo):
        print(f"üìñ Leyendo: {os.path.basename(archivo)}")
        
        with open(archivo, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        articulos = data.get('articles', [])
        database = data.get('database', 'Unknown')
        
        print(f"   ‚Ä¢ Base de datos: {database}")
        print(f"   ‚Ä¢ Art√≠culos: {len(articulos)}")
        
        estadisticas[database] = len(articulos)
        todos_articulos.extend(articulos)
        print()
    else:
        print(f"‚ö†Ô∏è  Archivo no encontrado: {archivo}\n")

# Eliminar duplicados por t√≠tulo
print("üîç Eliminando duplicados...")
articulos_unicos = []
titulos_vistos = set()

for articulo in todos_articulos:
    titulo = articulo.get('title', '').strip().lower()
    if titulo and titulo not in titulos_vistos:
        titulos_vistos.add(titulo)
        articulos_unicos.append(articulo)

duplicados = len(todos_articulos) - len(articulos_unicos)
print(f"   ‚Ä¢ Total art√≠culos: {len(todos_articulos)}")
print(f"   ‚Ä¢ Duplicados eliminados: {duplicados}")
print(f"   ‚Ä¢ Art√≠culos √∫nicos: {len(articulos_unicos)}\n")

# Crear archivo unificado
output_file = "data/unified_articles.json"
os.makedirs(os.path.dirname(output_file), exist_ok=True)

resultado = {
    "metadata": {
        "unified_date": datetime.now().isoformat(),
        "query": "generative artificial intelligence",
        "total_articles": len(articulos_unicos),
        "duplicates_removed": duplicados,
        "databases": estadisticas
    },
    "articles": articulos_unicos
}

with open(output_file, 'w', encoding='utf-8') as f:
    json.dump(resultado, f, indent=2, ensure_ascii=False)

print("="*80)
print("‚úÖ UNIFICACI√ìN COMPLETADA")
print("="*80 + "\n")

print("üìä Resumen por base de datos:")
for db, count in estadisticas.items():
    print(f"   ‚Ä¢ {db}: {count} art√≠culos")

print(f"\nüìÅ Archivo unificado guardado en: {output_file}")
print(f"üìö Total de art√≠culos √∫nicos: {len(articulos_unicos)}")
print("\n" + "="*80 + "\n")
