[
  {
    "id": "article_1",
    "title": "Education in the Era of Generative Artificial Intelligence (AI): Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning",
    "abstract": "Since its maiden release into the public domain on November 30, 2022, ChatGPT garnered more than one million subscribers within a week. The generative AI tool ⎼ChatGPT took the world by surprise with it sophisticated capacity to carry out remarkably complex tasks. The extraordinary abilities of ChatGPT to perform complex tasks within the field of education has caused mixed feelings among educators, as this advancement in AI seems to revolutionize existing educational praxis. This is an exploratory study that synthesizes recent extant literature to offer some potential benefits and drawbacks of ChatGPT in promoting teaching and learning. Benefits of ChatGPT include but are not limited to promotion of personalized and interactive learning, generating prompts for formative assessment activities that provide ongoing feedback to inform teaching and learning etc. The paper also highlights some inherent limitations in the ChatGPT such as generating wrong information, biases in data training, which may augment existing biases, privacy issues etc. The study offers recommendations on how ChatGPT could be leveraged to maximize teaching and learning. Policy makers, researchers, educators and technology experts could work together and start conversations on how these evolving generative AI tools could be used safely and constructively to improve education and support students’ learning.",
    "source": "semantic_scholar",
    "year": 2023,
    "authors": [
      "David Baidoo-Anu",
      "Leticia Owusu Ansah"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.2139/ssrn.4337484",
    "paper_id": "7b6a8c6d44e0f77bf930484e438d77b7465a69fb",
    "citation_count": 1834
  },
  {
    "id": "article_2",
    "title": "Experimental evidence on the productivity effects of generative artificial intelligence",
    "abstract": "We examined the productivity effects of a generative artificial intelligence (AI) technology, the assistive chatbot ChatGPT, in the context of midlevel professional writing tasks. In a preregistered online experiment, we assigned occupation-specific, incentivized writing tasks to 453 college-educated professionals and randomly exposed half of them to ChatGPT. Our results show that ChatGPT substantially raised productivity: The average time taken decreased by 40% and output quality rose by 18%. Inequality between workers decreased, and concern and excitement about AI temporarily rose. Workers exposed to ChatGPT during the experiment were 2 times as likely to report using it in their real job 2 weeks after the experiment and 1.6 times as likely 2 months after the experiment. Description Editor’s summary Automation has historically displaced human workers in factories (e.g., automotive manufacturing) or in performing routine computational tasks. Will generative artificial intelligence (AI) tools such as ChatGPT disrupt the labor market by making educated professionals obsolete, or will these tools complement their skills and enhance productivity? Noy and Zhang examined this issue in an experiment that recruited college-educated professionals to complete incentivized writing tasks. Participants assigned to use ChatGPT were more productive, efficient, and enjoyed the tasks more. Participants with weaker skills benefited the most from ChatGPT, which carries policy implications for efforts to reduce productivity inequality through AI. —EEU The assistive chatbot ChatGPT raises productivity in professional writing tasks and reduces productivity inequality.",
    "source": "semantic_scholar",
    "year": 2023,
    "authors": [
      "Shakked Noy",
      "Whitney Zhang"
    ],
    "keywords": [
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.1126/science.adh2586",
    "paper_id": "8d020275181c69e5e768c6ffc40e09710a6f54f1",
    "citation_count": 894
  },
  {
    "id": "article_3",
    "title": "Examining Science Education in ChatGPT: An Exploratory Study of Generative Artificial Intelligence",
    "abstract": "The advent of generative artificial intelligence (AI) offers transformative potential in the field of education. The study explores three main areas: (1) How did ChatGPT answer questions related to science education? (2) What are some ways educators could utilise ChatGPT in their science pedagogy? and (3) How has ChatGPT been utilised in this study, and what are my reflections about its use as a research tool? This exploratory research applies a self-study methodology to investigate the technology. Impressively, ChatGPT’s output often aligned with key themes in the research. However, as it currently stands, ChatGPT runs the risk of positioning itself as the ultimate epistemic authority, where a single truth is assumed without a proper grounding in evidence or presented with sufficient qualifications. Key ethical concerns associated with AI include its potential environmental impact, issues related to content moderation, and the risk of copyright infringement. It is important for educators to model responsible use of ChatGPT, prioritise critical thinking, and be clear about expectations. ChatGPT is likely to be a useful tool for educators designing science units, rubrics, and quizzes. Educators should critically evaluate any AI-generated resource and adapt it to their specific teaching contexts. ChatGPT was used as a research tool for assistance with editing and to experiment with making the research narrative clearer. The intention of the paper is to act as a catalyst for a broader conversation about the use of generative AI in science education.",
    "source": "semantic_scholar",
    "year": 2023,
    "authors": [
      "G. Cooper"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.1007/s10956-023-10039-y",
    "paper_id": "6f4486c3d8ccd638c2a6bcbfafa01b5a3225bcab",
    "citation_count": 778
  },
  {
    "id": "article_4",
    "title": "Promises and challenges of generative artificial intelligence for human learning",
    "abstract": "Generative artificial intelligence (GenAI) holds the potential to transform the delivery, cultivation and evaluation of human learning. Here the authors examine the integration of GenAI as a tool for human learning, addressing its promises and challenges from a holistic viewpoint that integrates insights from learning sciences, educational technology and human–computer interaction. GenAI promises to enhance learning experiences by scaling personalized support, diversifying learning materials, enabling timely feedback and innovating assessment methods. However, it also presents critical issues such as model imperfections, ethical dilemmas and the disruption of traditional assessments. Thus, cultivating AI literacy and adaptive skills is imperative for facilitating informed engagement with GenAI technologies. Rigorous research across learning contexts is essential to evaluate GenAI’s effect on human cognition, metacognition and creativity. Humanity must learn with and about GenAI, ensuring that it becomes a powerful ally in the pursuit of knowledge and innovation, rather than a crutch that undermines our intellectual abilities. This Perspective describes the roles of generative AI in providing personalized support, diversity and innovative assessment in learning. However, it also raises ethical concerns and highlights issues such as model imperfection, underscoring the need for AI literacy and adaptability.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Lixiang Yan",
      "Samuel Greiff",
      "Ziwen Teuber",
      "D. Gašević"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence"
    ],
    "doi": "10.1038/s41562-024-02004-5",
    "paper_id": "90a3410bc1632ba3340de7259186c66ba03f1668",
    "citation_count": 147
  },
  {
    "id": "article_5",
    "title": "Student perspectives on the use of generative artificial intelligence technologies in higher education",
    "abstract": "The aim of this project was to understand student perspectives on generative artificial intelligence (GAI) technologies such as Chat generative Pre-Trained Transformer (ChatGPT), in order to inform changes to the University of Liverpool Academic Integrity code of practice. The survey for this study was created by a library student team and vetted through focus groups. A total of 2555 students participated in the survey. Results showed that only 7% of students who responded had not heard of any GAI technologies, whilst over half had used or considered using these for academic purposes. The majority of students (54.1%) were supportive or somewhat supportive of using tools such as Grammarly, but 70.4% were unsupportive or somewhat unsupportive towards students using tools such as ChatGPT to write their whole essay. Students who had higher levels of confidence in their academic writing were less likely to use or consider using them for academic purposes, and were also less likely to be supportive of other students using them. Most students (41.1%) also thought there should be a university wide policy on when these technologies are or are not appropriate to use. The results of this research suggest that students require clear policies on the use of GAI and that these technologies should not be banned from university, but consideration must be made to ensure different groups of students have equal access to the technologies.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Heather Johnston",
      "Rebecca F. Wells",
      "Elizabeth M. Shanks",
      "Timothy Boey",
      "Bryony N. Parsons"
    ],
    "keywords": [
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.1007/s40979-024-00149-4",
    "paper_id": "3c10800ee7c707bbf5e9fdb371e1451f9d92e26d",
    "citation_count": 137
  },
  {
    "id": "article_6",
    "title": "Collaborating With ChatGPT: Considering the Implications of Generative Artificial Intelligence for Journalism and Media Education",
    "abstract": "Generative artificial intelligence (AI) is ushering in an era of potential transformation of journalism and media content. This essay considers one notable generative AI platform called ChatGPT made available to the public in 2022 for free use. ChatGPT allows users to enter text prompts and rapidly generates text responses drawn from its knowledge acquired via machine learning in engagement with the internet. This essay is coauthored by a human journalism and media professor in collaboration with ChatGPT. The essay demonstrates the capacity and limitations of ChatGPT and offers reflections on the implications of generative AI for journalism and media education.",
    "source": "semantic_scholar",
    "year": 2023,
    "authors": [
      "J. Pavlik"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence",
      "machine learning",
      "GPT"
    ],
    "doi": "10.1177/10776958221149577",
    "paper_id": "9dafa6c5c609348b46734fc8997b93b3587fec6e",
    "citation_count": 705
  },
  {
    "id": "article_7",
    "title": "Factors Influencing University Students’ Behavioral Intention to Use Generative Artificial Intelligence: Integrating the Theory of Planned Behavior and AI Literacy",
    "abstract": "Abstract Generative artificial intelligence (GAI) advancements have ignited new expectations for artificial intelligence (AI)-enabled educational transformations. Based on the theory of planned behavior (TPB), this study combines structural equation modeling and interviews to analyze the influencing factors of Chinese university students’ GAI technology usage intention. Regarding AI literacy, students’ cognitive literacy in AI ethics scored the highest (M = 5.740), while AI awareness literacy scored the lowest (M = 4.578). Students’ attitudes toward GAI significantly and positively influenced their usage intention, with the combined TPB framework and AI literacy explaining 59.3% of the variance. AI literacy and subjective norms positively influenced students’ attitudes toward GAI technology and perceived behavioral control, and attitude mediated the impact of AI literacy and subjective norms on GAI usage intention. Further, the interviews provide new insights for university management and educational leadership regarding the construction of an educational ecosystem under the application of GAI technology.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Chengliang Wang",
      "Haoming Wang",
      "Yuanyuan Li",
      "Jian Dai",
      "Xiaoqing Gu"
    ],
    "keywords": [
      "artificial intelligence"
    ],
    "doi": "10.1080/10447318.2024.2383033",
    "paper_id": "71353200a4f9757e10d0243e231fc5bcd14d8387",
    "citation_count": 133
  },
  {
    "id": "article_8",
    "title": "Beware of Metacognitive Laziness: Effects of Generative Artificial Intelligence on Learning Motivation, Processes, and Performance",
    "abstract": "With the continuous development of technological and educational innovation, learners nowadays can obtain a variety of supports from agents such as teachers, peers, education technologies, and recently, generative artificial intelligence such as ChatGPT. In particular, there has been a surge of academic interest in human‐AI collaboration and hybrid intelligence in learning. The concept of hybrid intelligence is still at a nascent stage, and how learners can benefit from a symbiotic relationship with various agents such as AI, human experts and intelligent learning systems is still unknown. The emerging concept of hybrid intelligence also lacks deep insights and understanding of the mechanisms and consequences of hybrid human‐AI learning based on strong empirical research. In order to address this gap, we conducted a randomised experimental study and compared learners' motivations, self‐regulated learning processes and learning performances on a writing task among different groups who had support from different agents, that is, ChatGPT (also referred to as the AI group), chat with a human expert, writing analytics tools, and no extra tool. A total of 117 university students were recruited, and their multi‐channel learning, performance and motivation data were collected and analysed. The results revealed that: (1) learners who received different learning support showed no difference in post‐task intrinsic motivation; (2) there were significant differences in the frequency and sequences of the self‐regulated learning processes among groups; (3) ChatGPT group outperformed in the essay score improvement but their knowledge gain and transfer were not significantly different. Our research found that in the absence of differences in motivation, learners with different supports still exhibited different self‐regulated learning processes, ultimately leading to differentiated performance. What is particularly noteworthy is that AI technologies such as ChatGPT may promote learners' dependence on technology and potentially trigger “metacognitive laziness”. In conclusion, understanding and leveraging the respective strengths and weaknesses of different agents in learning is critical in the field of future hybrid intelligence.\nWhat is already known about this topic\n\nHybrid intelligence, combining human and machine intelligence, aims to augment human capabilities rather than replace them, creating opportunities for more effective lifelong learning and collaboration.\nGenerative AI, such as ChatGPT, has shown potential in enhancing learning by providing immediate feedback, overcoming language barriers and facilitating personalised educational experiences.\nThe effectiveness of AI in educational contexts varies, with some studies highlighting its benefits in improving academic performance and motivation, while others note limitations in its ability to replace human teachers entirely.\nWhat this paper adds\n\nWe conducted a randomised experimental study in the lab setting and compared learners' motivations, self‐regulated learning processes and learning performances among different agent groups (AI, human expert and checklist tools).\nWe found that AI technologies such as ChatGPT may promote learners' dependence on technology and potentially trigger metacognitive \"laziness\", which can potentially hinder their ability to self‐regulate and engage deeply in learning.\nWe also found that ChatGPT can significantly improve short‐term task performance, but it may not boost intrinsic motivation and knowledge gain and transfer.\nImplications for practice and/or policy\n\nWhen using AI in learning, learners should focus on deepening their understanding of knowledge and actively engage in metacognitive processes such as evaluation, monitoring, and orientation, rather than blindly following ChatGPT's feedback solely to complete tasks efficiently.\nWhen using AI in teaching, teachers should think about which tasks are suitable for learners to complete with the assistance of AI, pay attention to stimulating learners' intrinsic motivations, and develop scaffolding to assist learners in active learning.\nResearcher should design multi‐task and cross‐context studies in the future to deepen our understanding of how learners could ethically and effectively learn, regulate, collaborate and evolve with AI.\n\n",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Yizhou Fan",
      "Luzhen Tang",
      "Huixiao Le",
      "Kejie Shen",
      "Shufang Tan"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.1111/bjet.13544",
    "paper_id": "97a5fb3512be8dfd9c8a32f4c556ad9db6030288",
    "citation_count": 137
  },
  {
    "id": "article_9",
    "title": "How should we change teaching and assessment in response to increasingly powerful generative Artificial Intelligence? Outcomes of the ChatGPT teacher survey",
    "abstract": "There has been widespread media commentary about the potential impact of generative Artificial Intelligence (AI) such as ChatGPT on the Education field, but little examination at scale of how educators believe teaching and assessment should change as a result of generative AI. This mixed methods study examines the views of educators (n = 318) from a diverse range of teaching levels, experience levels, discipline areas, and regions about the impact of AI on teaching and assessment, the ways that they believe teaching and assessment should change, and the key motivations for changing their practices. The majority of teachers felt that generative AI would have a major or profound impact on teaching and assessment, though a sizeable minority felt it would have a little or no impact. Teaching level, experience, discipline area, region, and gender all significantly influenced perceived impact of generative AI on teaching and assessment. Higher levels of awareness of generative AI predicted higher perceived impact, pointing to the possibility of an ‘ignorance effect’. Thematic analysis revealed the specific curriculum, pedagogy, and assessment changes that teachers feel are needed as a result of generative AI, which centre around learning with AI, higher-order thinking, ethical values, a focus on learning processes and face-to-face relational learning. Teachers were most motivated to change their teaching and assessment practices to increase the performance expectancy of their students and themselves. We conclude by discussing the implications of these findings in a world with increasingly prevalent AI.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Matthew S. Bower",
      "Jodie Torrington",
      "Jennifer W. M. Lai",
      "P. Petocz",
      "Mark Alfano"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.1007/s10639-023-12405-0",
    "paper_id": "5d2f65749187c7369072d7ecbe37784295ac5acd",
    "citation_count": 97
  },
  {
    "id": "article_10",
    "title": "Collaborative Working and Critical Thinking: Adoption of Generative Artificial Intelligence Tools in Higher Education",
    "abstract": "This study explores the impact of generative artificial intelligence tools on critical thinking and collaboration among university students, highlighting the importance of investigating these technologies due to their increasing integration into higher education and their potential to transform traditional pedagogical practices. A predominantly female sample was surveyed to assess their familiarity with and experience and perceptions of these tools. A total of 87% of the respondents had prior knowledge of generative AI tools, with 38% using them occasionally. Among the most popular tools are Canva 2024 (33%), Chat PDF (26%), and YOU.COM (24%). Additionally, 64% of the respondents believe that these tools significantly improve their critical thinking ability. Despite their high familiarity with and occasional use of these tools, the need for continuous training and technical support was identified. While generative AI tools show promising potential for enhancing collaboration and critical thinking in higher education, previous research has limitations, such as the lack of longitudinal data and the inadequacy in addressing ethical considerations and potential biases. More comprehensive research is needed to understand their long-term impact better and maximize their potential benefits.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Lena Ivannova Ruiz-Rojas",
      "Luis Salvador-Ullauri",
      "Patricia Acosta-Vargas"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence"
    ],
    "doi": "10.3390/su16135367",
    "paper_id": "4e9fefd759c0d0f920533cd70676a59e291729e2",
    "citation_count": 95
  },
  {
    "id": "article_11",
    "title": "Generative Artificial Intelligence in Education: From Deceptive to Disruptive",
    "abstract": "Generative Artificial Intelligence (GenAI) has emerged as a promising technology that can create original content, such as text, images, and sound. The use of GenAI in educational settings is becoming increasingly popular and offers a range of opportunities and challenges. This special issue explores the management and integration of GenAI in educational settings, including the ethical considerations, best practices, and opportunities. The potential of GenAI in education is vast. By using algorithms and data, GenAI can create original content that can be used to augment traditional teaching methods, creating a more interactive and personalized learning experience. In addition, GenAI can be utilized as an assessment tool and for providing feedback to students using generated content. For instance, it can be used to create custom quizzes, generate essay prompts, or even grade essays. The use of GenAI as an assessment tool can reduce the workload of teachers and help students receive prompt feedback on their work. Incorporating GenAI in educational settings also poses challenges related to academic integrity. With availability of GenAI models, students can use them to study or complete their homework assignments, which can raise concerns about the authenticity and authorship of the delivered work. Therefore, it is important to ensure that academic standards are maintained, and the originality of the student's work is preserved. This issue highlights the need for implementing ethical practices in the use of GenAI models and ensuring that the technology is used to support and not replace the student's learning experience.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "M. A. Forment",
      "F. García-Peñalvo",
      "J. Camba"
    ],
    "keywords": [
      "artificial intelligence"
    ],
    "doi": "10.9781/ijimai.2024.02.011",
    "paper_id": "08ff8980b5135bb6b8da9f0022001aad1d400d15",
    "citation_count": 85
  },
  {
    "id": "article_12",
    "title": "Knowledge Management Perspective of Generative Artificial Intelligence",
    "abstract": "In this editorial, revisiting Alavi and Leidner (2001) as a conceptual lens, we consider the organizational implications of Generative Artificial Intelligence (GenAI) from a knowledge management (KM) perspective. We examine how GenAI impact the processes of knowledge creation, storage, transfer, and application, highlighting both the opportunities and challenges this technology presents. In knowledge creation, GenAI enhances information? processing and cognitive functions, fostering individual and organizational learning. However, it also introduces risks like AI bias and reduced human socialization, potentially marginalizing junior knowledge workers. For knowledge storage and retrieval, GenAI’s ability to quickly access vast knowledge bases significantly changes employee interactions with KM systems. This raises questions about balancing human-derived tacit knowledge with AI-generated explicit knowledge. The paper also explores GenAI’s role in knowledge transfer, particularly in training and cultivating a learning culture. Challenges include an over-reliance on AI and risks in disseminating sensitive information. In terms of knowledge application, GenAI is seen as a tool to boost productivity and innovation, but issues like knowledge misapplication, intellectual property, and ethical considerations are critical. Conclusively, the paper argues for a balanced approach to integrating GenAI into KM processes. It advocates for harmonizing GenAI’s capabilities with human insights to effectively manage knowledge in contemporary organizations, ensuring both technological advances and ethical responsibility.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Maryam Alavi",
      "D. Leidner",
      "Reza Mousavi"
    ],
    "keywords": [
      "artificial intelligence"
    ],
    "doi": "10.17705/1jais.00859",
    "paper_id": "d7a8a9229a3a4d41be63ecfbbacd825bccb30d09",
    "citation_count": 76
  },
  {
    "id": "article_13",
    "title": "Using Generative Artificial Intelligence Tools to Explain and Enhance Experiential Learning for Authentic Assessment",
    "abstract": "The emergence of generative artificial intelligence (GenAI) requires innovative educational environments to leverage this technology effectively to address concerns like academic integrity, plagiarism, and others. Additionally, higher education needs effective pedagogies to achieve intended learning outcomes. This emphasizes the need to redesign active learning experiences in the GenAI era. Authentic assessment and experiential learning are two possible meaningful alternatives in this context. Accordingly, this article investigates how GenAI can enhance teaching and learning by constructively addressing study situations beyond conventional learning approaches and cultivating high-order skills and knowledge acquisition. This study employs thing ethnography to examine GenAI tools’ integration with authentic assessment and experiential learning and explore implementation alternatives. The results reveal insights into creating human-centered and GenAI-enhanced learning experiences within a constructive alignment. Specific examples are also provided to guide their implementation. Our contributions extend beyond the traditional use of GenAI tools as mere agents-to-write or agents-to-answer questions to become agents-to-support experiential learning for authentic assessment. These findings underscore the transformative role of GenAI tools in enhancing teaching and learning efficacy and effectiveness. The limitations in treating GenAI tools as subjects in thing ethnography are acknowledged, with potential for future implementation evaluation.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "D. Salinas-Navarro",
      "E. Vilalta-Perdomo",
      "Rosario Michel-Villarreal",
      "Luis Montesinos"
    ],
    "keywords": [
      "artificial intelligence"
    ],
    "doi": "10.3390/educsci14010083",
    "paper_id": "b71fb682b835500ba19e654584a05c4bb6e65c10",
    "citation_count": 80
  },
  {
    "id": "article_14",
    "title": "Developing evaluative judgement for a time of generative artificial intelligence",
    "abstract": "Abstract Generative artificial intelligence (AI) has rapidly increased capacity for producing textual, visual and auditory outputs, yet there are ongoing concerns regarding the quality of those outputs. There is an urgent need to develop students’ evaluative judgement – the capability to judge the quality of work of self and others – in recognition of this new reality. In this conceptual paper, we describe the intersection between evaluative judgement and generative AI with a view to articulating how assessment practices can help students learn to work productively with generative AI. We propose three foci: (1) developing evaluative judgement of generative AI outputs; (2) developing evaluative judgement of generative AI processes; and (3) generative AI assessment of student evaluative judgements. We argue for developing students’ capabilities to identify and calibrate quality of work – uniquely human capabilities at a time of technological acceleration – through existing formative assessment strategies. These approaches circumvent and interrupt students’ uncritical usage of generative AI. The relationship between evaluative judgement and generative AI is more than just the application of human judgement to machine outputs. We have a collective responsibility, as educators and learners, to ensure that humans do not relinquish their roles as arbiters of quality.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "M. Bearman",
      "Joanna Tai",
      "P. Dawson",
      "D. Boud",
      "R. Ajjawi"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence"
    ],
    "doi": "10.1080/02602938.2024.2335321",
    "paper_id": "5bea14c265e81127f282298ee1274f2b8c2de160",
    "citation_count": 66
  },
  {
    "id": "article_15",
    "title": "A Human-Centered Learning and Teaching Framework Using Generative Artificial Intelligence for Self-Regulated Learning Development Through Domain Knowledge Learning in K–12 Settings",
    "abstract": "The advent of generative artificial intelligence (AI) has ignited an increase in discussions about generative AI tools in education. In this study, a human-centered learning and teaching framework that uses generative AI tools for self-regulated learning development through domain knowledge learning was proposed to catalyze changes in educational practices. The framework illustrates how generative AI tools can revolutionize educational practices and transform the processes of teaching and learning to become human-centered. It emphasizes the evolving roles of teachers, who increasingly become skillful facilitators and humanistic storytellers who craft differentiated instructions and attempt to develop students’ individualized learning. Drawing upon insights from neuroscience, the framework guides students to employ generative AI tools to augment their attentiveness, stimulate active engagement in learning, receive immediate feedback, and encourage self-reflection. The pedagogical approach is also reimagined; teachers equipped with generative AI tools and AI literacy can refine their teaching strategies to better equip students to meet future challenges. The practical application of the framework is demonstrated in a case study involving the development of Chinese language writing ability among primary students within a K–12 educational context. This article also reports the results of a 60-h development programme for teachers. Specifically, providing in-service teachers with cases involving uses of the proposed framework helped them to better understand the generative AI concepts and integrate them into their teaching and learning and increased their perceived ability to design AI-integrated courses that would enhance students’ attention, engagement, confidence, and satisfaction.",
    "source": "ieee",
    "year": 2024,
    "authors": [
      "Siu-Cheung Kong",
      "Yin Yang"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence"
    ],
    "doi": "10.1109/TLT.2024.3392830",
    "paper_id": "f710896031d29efc4aaa2abe302db3c6f8332248",
    "citation_count": 63
  },
  {
    "id": "article_16",
    "title": "Navigating Generative Artificial Intelligence Promises and Perils for Knowledge and Creative Work",
    "abstract": "Generative artificial intelligence (GenAI) is rapidly becoming a viable tool to enhance productivity and act as a catalyst for innovation across various sectors. Its ability to perform tasks that have traditionally required human judgment and creativity is transforming knowledge and creative work. Yet it also raises concerns and implications that could reshape the very landscape of knowledge and creative work. In this editorial, we undertake an in-depth examination of both the opportunities and challenges presented by GenAI for future IS research.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Hind Benbya",
      "Franz Strich",
      "Toomas Tamm"
    ],
    "keywords": [
      "artificial intelligence"
    ],
    "doi": "10.17705/1jais.00861",
    "paper_id": "8694bb2b5a2bb0cc88121160280e071fe34f94e6",
    "citation_count": 63
  },
  {
    "id": "article_17",
    "title": "An Empirical Evaluation of a Generative Artificial Intelligence Technology Adoption Model from Entrepreneurs' Perspectives",
    "abstract": "Technologies, such as Chat Generative Pre-Trained Transformer (ChatGPT, Smart PLS version 4), are prime examples of Generative Artificial Intelligence (AI), which is a constantly evolving area. SMEs, particularly startups, can obtain a competitive edge, innovate their business models, gain business value, and undergo a digital transformation by implementing these technologies. Continuous but gradual experimentation with these technologies is the foundation for their adoption. The experience that comes from trying new technologies can help entrepreneurs adopt new technologies more strategically and experiment more with them. The urgent need for an in-depth investigation is highlighted by the paucity of previous research on ChatGPT uptake in the startup context, particularly from an entrepreneurial perspective. The objective of this research study is to empirically validate the Generative AI technology adoption model to establish the direction and strength of the correlations among the adoption factors from the perspectives of the entrepreneurs. The data are collected from 482 entrepreneurs who exhibit great diversity in their genders, the countries in which their startups are located, the industries their startups serve, their age, their educational levels, their work experience as entrepreneurs, and the length of time the startups have been on the market. Collected data are analyzed using the Partial Least Squares Structural Equation Modeling (PLS-SEM) technique, which results in a statistical examination of the relationships between the adoption model’s factors. The results indicate that social influence, domain experience, technology familiarity, system quality, training and support, interaction convenience, and anthropomorphism are the factors that impact the pre-perception and perception phase of adoption. These factors motivate entrepreneurs to experiment more with the technology, thereby building perceptions of its usefulness, perceived ease of use, and perceived enjoyment, three factors that in turn affect emotions toward the technology and, finally, switching intentions. Control variables like age, gender, and educational attainment have no appreciable effect on switching intentions to alternatives of the Generative AI technology. Rather, the experience factor of running businesses shows itself to be a crucial one. The results have practical implications for entrepreneurs and other innovation ecosystem actors, including, for instance, technology providers, libraries, and policymakers. This research study enriches the Generative AI technology acceptance theory and extends the existing literature by introducing new adoption variables and stages specific to entrepreneurship.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Varun Gupta"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.3390/systems12030103",
    "paper_id": "106cdc3f272e61d73a944aae9a4497ef67d0c6e1",
    "citation_count": 52
  },
  {
    "id": "article_18",
    "title": "Student Perceptions of Generative Artificial Intelligence: Investigating Utilization, Benefits, and Challenges in Higher Education",
    "abstract": "This research explores the use of Generative Artificial Intelligence (GenAI) tools among higher education students in Saudi Arabia, aiming to understand their current perceptions of these technologies. This study utilizes the Technology Acceptance Model (TAM) and the theory of Task-Technology Fit (TTF) to examine students’ utilization, perceived benefits, and challenges associated with these tools. A cross-sectional survey was conducted, yielding 859 responses. The findings indicate that 78.7% of students frequently use GenAI tools, while 21.3% do not, often due to a lack of knowledge or interest. ChatGPT emerged as the most widely used GenAI tool, utilized by 86.2% of respondents, followed by other tools like Gemini, Socratic, and CoPilot. Students primarily use these tools for defining or clarifying concepts, translation, generating ideas in writing, and summarizing academic literature. They cite benefits such as ease of access, time-saving, and instant feedback. However, they express concerns about the challenges, including subscription fees, unreliable information, plagiarism, reduced human-to-human interaction, and impacts on learning autonomy. This study underscores the need for increased awareness, ethical guidelines, and robust academic integrity measures to ensure the responsible use of GenAI tools in educational settings. These findings highlight the need for a balanced utilization of GenAI tools in higher education that maximizes benefits while addressing potential challenges and guides the development of policies, curricula, and support systems.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Ahmad Almassaad",
      "Haya A. Alajlan",
      "Reem Alebaikan"
    ],
    "keywords": [
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.3390/systems12100385",
    "paper_id": "194fc8aeb4ae89175b5915f203a159b84ef6a97d",
    "citation_count": 55
  },
  {
    "id": "article_19",
    "title": "GPT, large language models (LLMs) and generative artificial intelligence (GAI) models in geospatial science: a systematic review",
    "abstract": "ABSTRACT The launch of large language models (LLMs) like ChatGPT in late 2022 and the anticipated arrival of future GPT-x iterations have marked the beginning of the generative artificial intelligence (GAI) era. We conducted a systematic review of how to integrate LLMs including GPT and other GAI models into geospatial science, based on 293 papers obtained from four databases of academic publications – Web of Science (WoS), Scopus, SSRN and arXiv – 26 papers were eventually included for analysis. We statistically outlined the share of domains where LLMs and other GAI models, the type of data that have been used for these models, and the modelling tasks and roles that they play. We also pointed out the challenges and future directions for the next research agenda – along with which we could better position ourselves in the mainstream of science and the cutting-edge research paradigm as others leverage insights from the growing data deluge.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Siqin Wang",
      "Tao Hu",
      "Huang Xiao",
      "Yun Li",
      "Ce Zhang"
    ],
    "keywords": [
      "artificial intelligence",
      "GPT",
      "large language models",
      "LLM"
    ],
    "doi": "10.1080/17538947.2024.2353122",
    "paper_id": "2d30e8e8ea25803f1ae0fb1ca97c1e48bb3c32fa",
    "citation_count": 53
  },
  {
    "id": "article_20",
    "title": "Generative Artificial Intelligence in Higher Education: Exploring Ways of Harnessing Pedagogical Practices with the Assistance of ChatGPT",
    "abstract": "There is a growing interest in using generative artificial intelligence (AI) for educational purposes within the higher education environments, while AI applications (such as ChatGPT) can transform traditional teaching and learning methods. ChatGPT is an advanced AI tool that generates new content and human-like responses. The purpose of this paper is to use ChatGPT as a research assistant in order to explore ways AI can be harnessed to enhance pedagogical practices in higher education. This is a qualitative study, in which the output-responses generated by ChatGPT provided a starting point for the investigation. AI can be harnessed to enhance pedagogical practices in higher education in various ways including personalized learning, automated assessment and feedback generation, virtual assistants and chatbots, content creation, resource recommendation, time management, language translation and support, research assistance, simulations and virtual labs. Other educational affordances that can strengthen the teaching and learning experience regard collaboration and communication, accessibility and inclusivity, as well as AI literacy. When implementing AI tools such as ChatGPT in higher education, ethical considerations (e.g., data privacy, transparency, accessibility, cultural sensitivity), potential misuses and concerns need to also be addressed. Although ChatGPT can aid the generation of content-ideas for further exploration, it is a complementary-supportive tool, and its output necessitates human evaluation and review. The integration of ChatGPT and other AI tools in the higher educational process/practices has implications for educators, students, design of curricula, and university policy makers.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "K. Nikolopoulou"
    ],
    "keywords": [
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.47852/bonviewijce42022489",
    "paper_id": "600112f1df7a5805848d24efcc4c687d4581aca3",
    "citation_count": 55
  },
  {
    "id": "article_21",
    "title": "A scoping review on how generative artificial intelligence transforms assessment in higher education",
    "abstract": "Generative artificial intelligence provides both opportunities and challenges for higher education. Existing literature has not properly investigated how this technology would impact assessment in higher education. This scoping review took a forward-thinking approach to investigate how generative artificial intelligence transforms assessment in higher education. We used the PRISMA extension for scoping reviews to select articles for review and report the results. In the screening, we retrieved 969 articles and selected 32 empirical studies for analysis. Most of the articles were published in 2023. We used three levels—students, teachers, and institutions—to analyses the articles. Our results suggested that assessment should be transformed to cultivate students’ self-regulated learning skills, responsible learning, and integrity. To successfully transform assessment in higher education, the review suggested that (i) teacher professional development activities for assessment, AI, and digital literacy should be provided, (ii) teachers’ beliefs about human and AI assessment should be strengthened, and (iii) teachers should be innovative and holistic in their teaching to reflect the assessment transformation. Educational institutions are recommended to review and rethink their assessment policies, as well as provide more inter-disciplinary programs and teaching.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Qi Xia",
      "Xiaojing Weng",
      "Ouyang Fan",
      "Tzung-Jin Lin",
      "T. Chiu"
    ],
    "keywords": [
      "artificial intelligence"
    ],
    "doi": "10.1186/s41239-024-00468-z",
    "paper_id": "de0ee1e7970e9ffff4add57f1fe72623453dae19",
    "citation_count": 110
  },
  {
    "id": "article_22",
    "title": "Enhancing Work Productivity through Generative Artificial Intelligence: A Comprehensive Literature Review",
    "abstract": "In this review, utilizing the PRISMA methodology, a comprehensive analysis of the use of Generative Artificial Intelligence (GAI) across diverse professional sectors is presented, drawing from 159 selected research publications. This study provides an insightful overview of the impact of GAI on enhancing institutional performance and work productivity, with a specific focus on sectors including academia, research, technology, communications, agriculture, government, and business. It highlights the critical role of GAI in navigating AI challenges, ethical considerations, and the importance of analytical thinking in these domains. The research conducts a detailed content analysis, uncovering significant trends and gaps in current GAI applications and projecting future prospects. A key aspect of this study is the bibliometric analysis, which identifies dominant tools like Chatbots and Conversational Agents, notably ChatGPT, as central to GAI’s evolution. The findings indicate a robust and accelerating trend in GAI research, expected to continue through 2024 and beyond. Additionally, this study points to potential future research directions, emphasizing the need for improved GAI design and strategic long-term planning, particularly in assessing its impact on user experience across various professional fields.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Humaid Al Naqbi",
      "Zied Bahroun",
      "Vian Ahmed"
    ],
    "keywords": [
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.3390/su16031166",
    "paper_id": "cc4a3422e011ca4715403f3bd818d37dc32d9d84",
    "citation_count": 150
  },
  {
    "id": "article_23",
    "title": "Publishers’ and journals’ instructions to authors on use of generative artificial intelligence in academic and scientific publishing: bibliometric analysis",
    "abstract": "Abstract Objectives To determine the extent and content of academic publishers’ and scientific journals’ guidance for authors on the use of generative artificial intelligence (GAI). Design Cross sectional, bibliometric study. Setting Websites of academic publishers and scientific journals, screened on 19-20 May 2023, with the search updated on 8-9 October 2023. Participants Top 100 largest academic publishers and top 100 highly ranked scientific journals, regardless of subject, language, or country of origin. Publishers were identified by the total number of journals in their portfolio, and journals were identified through the Scimago journal rank using the Hirsch index (H index) as an indicator of journal productivity and impact. Main outcome measures The primary outcomes were the content of GAI guidelines listed on the websites of the top 100 academic publishers and scientific journals, and the consistency of guidance between the publishers and their affiliated journals. Results Among the top 100 largest publishers, 24% provided guidance on the use of GAI, of which 15 (63%) were among the top 25 publishers. Among the top 100 highly ranked journals, 87% provided guidance on GAI. Of the publishers and journals with guidelines, the inclusion of GAI as an author was prohibited in 96% and 98%, respectively. Only one journal (1%) explicitly prohibited the use of GAI in the generation of a manuscript, and two (8%) publishers and 19 (22%) journals indicated that their guidelines exclusively applied to the writing process. When disclosing the use of GAI, 75% of publishers and 43% of journals included specific disclosure criteria. Where to disclose the use of GAI varied, including in the methods or acknowledgments, in the cover letter, or in a new section. Variability was also found in how to access GAI guidelines shared between journals and publishers. GAI guidelines in 12 journals directly conflicted with those developed by the publishers. The guidelines developed by top medical journals were broadly similar to those of academic journals. Conclusions Guidelines by some top publishers and journals on the use of GAI by authors are lacking. Among those that provided guidelines, the allowable uses of GAI and how it should be disclosed varied substantially, with this heterogeneity persisting in some instances among affiliated publishers and journals. Lack of standardization places a burden on authors and could limit the effectiveness of the regulations. As GAI continues to grow in popularity, standardized guidelines to protect the integrity of scientific output are needed.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Conner Ganjavi",
      "M. Eppler",
      "Asli Pekcan",
      "Brett Biedermann",
      "Andre Abreu"
    ],
    "keywords": [
      "artificial intelligence"
    ],
    "doi": "10.1136/bmj-2023-077192",
    "paper_id": "676b1c74535efca92fbb79a26ea66df9ea07e7e7",
    "citation_count": 131
  },
  {
    "id": "article_24",
    "title": "Factors influencing students’ acceptance and use generative artificial intelligence in elementary education: an expansion of the UTAUT model",
    "abstract": "This paper discusses Factors influencing students’ acceptance and use generative artificial intelligence in elementary education: an expansion of the UTAUT model. Published in Education and Information Technologies : Official Journal of the IFIP technical committee on Education. Citations: 44.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Lei Du",
      "Beibei Lv"
    ],
    "keywords": [
      "artificial intelligence"
    ],
    "doi": "10.1007/s10639-024-12835-4",
    "paper_id": "572ea2fe179dc1c63367dadc49e00eb171046662",
    "citation_count": 44
  },
  {
    "id": "article_25",
    "title": "The persuasive effects of political microtargeting in the age of generative artificial intelligence",
    "abstract": "Abstract The increasing availability of microtargeted advertising and the accessibility of generative artificial intelligence (AI) tools, such as ChatGPT, have raised concerns about the potential misuse of large language models in scaling microtargeting efforts for political purposes. Recent technological advancements, involving generative AI and personality inference from consumed text, can potentially create a highly scalable “manipulation machine” that targets individuals based on their unique vulnerabilities without requiring human input. This paper presents four studies examining the effectiveness of this putative “manipulation machine.” The results demonstrate that personalized political ads tailored to individuals’ personalities are more effective than nonpersonalized ads (studies 1a and 1b). Additionally, we showcase the feasibility of automatically generating and validating these personalized ads on a large scale (studies 2a and 2b). These findings highlight the potential risks of utilizing AI and microtargeting to craft political messages that resonate with individuals based on their personality traits. This should be an area of concern to ethicists and policy makers.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Almog Simchon",
      "Matthew Edwards",
      "Stephan Lewandowsky"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence",
      "GPT",
      "large language models"
    ],
    "doi": "10.1093/pnasnexus/pgae035",
    "paper_id": "46694f750ff97513e48b5eb8b52c2184d5840b2b",
    "citation_count": 71
  },
  {
    "id": "article_26",
    "title": "The Short-Term Effects of Generative Artificial Intelligence on Employment: Evidence from an Online Labor Market",
    "abstract": "Generative artificial intelligence (AI) holds the potential to either complement workers by enhancing their productivity or substitute them. We examine the short-term effects of the recently released generative AI models (ChatGPT, DALL-E 2, and Midjourney) on the employment outcomes of freelancers on a large online platform. We find that freelancers in highly affected occupations suffer from the introduction of generative AI, experiencing reductions in both employment and earnings. We find similar effects studying the release of other image-based generative AI models. Exploring the heterogeneity by freelancers’ employment history, we do not find evidence that high-quality service, measured by their past performance and employment, moderates the adverse effects on employment. In fact, we find suggestive evidence that top freelancers are disproportionately affected by AI. These results suggest that generative AI may transform the role of human capital in the organization and reduce overall demand for workers. Supplemental Material: The online appendices are available at https://doi.org/10.1287/orsc.2023.18441 .",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Xiang Hui",
      "O. Reshef",
      "Luofeng Zhou"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.2139/ssrn.4527336",
    "paper_id": "47bef342b9e1204a1360ef087556bd1243c65e59",
    "citation_count": 82
  },
  {
    "id": "article_27",
    "title": "Higher Education Students' Task Motivation in the Generative Artificial Intelligence Context: The Case of ChatGPT",
    "abstract": "Artificial intelligence has been attracting the attention of educational researchers recently, especially ChatGPT as a generative artificial intelligence tool. The context of generative artificial intelligence could impact different aspects of students’ learning, such as the motivational aspect. The present research intended to investigate the characteristics of students’ task motivation in the artificial intelligence context, specifically in the ChatGPT context. The researchers interviewed 15 students about their experiences with ChatGPT to collect data. The researchers used inductive and deductive content analysis to investigate students’ motivation when learning with ChatGPT. To arrive at the categories and sub-categories of students’ motivation, the researchers used the MAXQDA 2022. Five main categories emerged: task enjoyment, reported effort, result assessment, perceived relevance, and interaction. Each category comprised at least two sub-categories, and each sub-category was further organized into codes. The results indicated more positive characteristics of motivation than negative ones. The previous results could be due to the conversational or social aspect of the chatbot, enabling relationships with humans and enabling the maintenance of good quality conversations with them. We conclude that a generative AI could be utilized in educational settings to promote students’ motivation to learn and thus raise their learning achievement.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Mohammad Hmoud",
      "Hadeel Swaity",
      "Nardin Hamad",
      "Omar Karram",
      "Wajeeh M. Daher"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.3390/info15010033",
    "paper_id": "63dcc16b918c6fced2b10e721a8c4bf09d5582be",
    "citation_count": 70
  },
  {
    "id": "article_28",
    "title": "Unveiling the landscape of generative artificial intelligence in education: a comprehensive taxonomy of applications, challenges, and future prospects",
    "abstract": "This paper discusses Unveiling the landscape of generative artificial intelligence in education: a comprehensive taxonomy of applications, challenges, and future prospects. Published in Education and Information Technologies : Official Journal of the IFIP technical committee on Education. Citations: 66.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "A. Samala",
      "Soha Rawas",
      "Tianchong Wang",
      "J. M. Reed",
      "Jinhee Kim"
    ],
    "keywords": [
      "artificial intelligence"
    ],
    "doi": "10.1007/s10639-024-12936-0",
    "paper_id": "209330e2b9228629f8eb651d1de14c79909116a5",
    "citation_count": 66
  },
  {
    "id": "article_29",
    "title": "A Primer on Generative Artificial Intelligence",
    "abstract": "Many educators and professionals in different industries may need to become more familiar with the basic concepts of artificial intelligence (AI) and generative artificial intelligence (Gen-AI). Therefore, this paper aims to introduce some of the basic concepts of AI and Gen-AI. The approach of this explanatory paper is first to introduce some of the underlying concepts, such as artificial intelligence, machine learning, deep learning, artificial neural networks, and large language models (LLMs), that would allow the reader to better understand generative AI. The paper also discusses some of the applications and implications of generative AI on businesses and education, followed by the current challenges associated with generative AI.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Faisal Kalota"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence",
      "machine learning",
      "deep learning",
      "neural networks",
      "large language models",
      "LLM"
    ],
    "doi": "10.3390/educsci14020172",
    "paper_id": "ed90ca3acf39066225e9f8e1d6d5b5de2a878361",
    "citation_count": 70
  },
  {
    "id": "article_30",
    "title": "Generative artificial intelligence in supply chain and operations management: a capability-based framework for analysis and implementation",
    "abstract": "This research examines the transformative potential of artificial intelligence (AI) in general and Generative AI (GAI) in particular in supply chain and operations management (SCOM). Through the lens of the resource-based view and based on key AI capabilities such as learning, perception, prediction, interaction, adaptation, and reasoning, we explore how AI and GAI can impact 13 distinct SCOM decision-making areas. These areas include but are not limited to demand forecasting, inventory management, supply chain design, and risk management. With its outcomes, this study provides a comprehensive understanding of AI and GAI's functionality and applications in the SCOM context, offering a practical framework for both practitioners and researchers. The proposed framework systematically identifies where and how AI and GAI can be applied in SCOM, focussing on decision-making enhancement, process optimisation, investment prioritisation, and skills development. Managers can use it as a guidance to evaluate their operational processes and identify areas where AI and GAI can deliver improved efficiency, accuracy, resilience, and overall effectiveness. The research underscores that AI and GAI, with their multifaceted capabilities and applications, open a revolutionary potential and substantial implications for future SCOM practices, innovations, and research.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Ilya Jackson",
      "Dmitry A. Ivanov",
      "Alexandre Dolgui",
      "Jafar Namdar"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence"
    ],
    "doi": "10.1080/00207543.2024.2309309",
    "paper_id": "14faed00db373d87bf90e8ee8f2c0dbbeed768dd",
    "citation_count": 151
  },
  {
    "id": "article_31",
    "title": "Generative artificial intelligence in primary care: an online survey of UK general practitioners",
    "abstract": "Objectives Following the launch of ChatGPT in November 2022, interest in large language model-powered chatbots has soared with increasing focus on the clinical potential of these tools. We sought to measure general practitioners’ (GPs) current use of this new generation of chatbots to assist with any aspect of clinical practice in the UK. Methods An online survey was distributed to a non-probability sample of GPs registered with the clinician marketing service Doctors.net.uk. The study was launched as a monthly ‘omnibus survey’ which has a predetermined sample size of 1000 participants. Results 531 (53%) respondents were men, 544 (54%) were 46 years or older. 20% (205) reported using generative artificial intelligence (AI) tools in clinical practice; of those who answered affirmatively and were invited to clarify further, 29% (47) reported using these tools to generate documentation after patient appointments and 28% (45) to suggest a differential diagnosis. Discussion Administered a year after ChatGPT was launched, this is the largest survey we know of conducted into doctors’ use of generative AI in clinical practice. Findings suggest that GPs may derive value from these tools, particularly with administrative tasks and to support clinical reasoning. Conclusion Despite a lack of guidance about these tools and unclear work policies, GPs report using generative AI to assist with their job. The medical community will need to find ways to both educate physicians and trainees and guide patients about the safe adoption of these tools.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "C. Blease",
      "Cosima Locher",
      "Jens Gaab",
      "M. Hägglund",
      "K. Mandl"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.1136/bmjhci-2024-101102",
    "paper_id": "7d7f20d8822e4dd444fb5788c1fa354a3f2a0401",
    "citation_count": 61
  },
  {
    "id": "article_32",
    "title": "Generative Artificial Intelligence in Business: Towards a Strategic Human Resource Management Framework",
    "abstract": "As businesses and society navigate the potentials of generative artificial intelligence (GAI), the integration of these technologies introduces unique challenges and opportunities for human resources, requiring a re‐evaluation of human resource management (HRM) frameworks. The existing frameworks may often fall short of capturing the novel attributes, complexities and impacts of GAI on workforce dynamics and organizational operations. This paper proposes a strategic HRM framework, underpinned by the theory of institutional entrepreneurship for sustainable organizations, for integrating GAI within HRM practices to boost operational efficiency, foster innovation and secure a competitive advantage through responsible practices and workforce development. Central to this framework is the alignment with existing business objectives, seizing opportunities, strategic resource assessment and orchestration, re‐institutionalization, realignment and embracing a culture of continuous learning and adaptation. This approach provides a detailed roadmap for organizations to navigate successfully the complexities of a GAI‐enhanced business environment. Additionally, this paper significantly contributes to the theoretical discourse by bridging the gap between HRM and GAI adoption, the proposed framework accounting for GAI–human capital symbiosis, setting the stage for future research to empirically test its applicability, explore its implications on HRM practices and understand its broader economic and societal consequences through diverse multi‐disciplinary and multi‐level research methodologies.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Soumyadeb Chowdhury",
      "P. Budhwar",
      "Geoffrey Wood"
    ],
    "keywords": [
      "artificial intelligence"
    ],
    "doi": "10.1111/1467-8551.12824",
    "paper_id": "326b9ad69a7e60e84fbff2b1d2d2c858952b17fd",
    "citation_count": 58
  },
  {
    "id": "article_33",
    "title": "Promoting sustainable development goals through generative artificial intelligence in the digital supply chain: Insights from Chinese tourism SMEs",
    "abstract": "Interdisciplinary advancements, such as generative artificial intelligence (AI) and digital supply chains, can significantly contribute to achieving sustainable development goals (SDGs), particularly within tourism. This paper illuminates how it works well, focusing on the underexplored area of Environmental, Social, and Governance (ESG) performance within small and medium‐sized tourism enterprises (SMEs) in China. Through a survey of 429 international SMEs, we apply the Resource‐Based View and Dynamic Capabilities Theory to investigate how generative AI, such as ChatGPT, in digital supply chains can enhance innovation, collaboration, and, ultimately, ESG performance. The empirical findings underscore the pivotal role of generative AI in augmenting ESG performance via bolstering innovation and collaboration within digital supply chains. Additionally, the moderating effect of customer involvement positively influences the relationship between the digital supply chain and ESG performance. By demonstrating these relations, our study contributes to theoretical and practical efforts toward sustainable tourism and the broader achievement of the SDGs.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Shaofeng Wang",
      "Hao Zhang"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.1002/sd.3152",
    "paper_id": "4e3cf7e4bf27ead052eba05720c133276a12286c",
    "citation_count": 56
  },
  {
    "id": "article_34",
    "title": "Inadequacies of Large Language Model Benchmarks in the Era of Generative Artificial Intelligence",
    "abstract": "The rapid rise in popularity of Large Language Models (LLMs) with emerging capabilities has spurred public curiosity to evaluate and compare different LLMs, leading many researchers to propose their own LLM benchmarks. Noticing preliminary inadequacies in those benchmarks, we embarked on a study to critically assess 23 state-of-the-art LLM benchmarks, using our novel unified evaluation framework through the lenses of people, process, and technology, under the pillars of benchmark functionality and integrity. Our research uncovered significant limitations, including biases, difficulties in measuring genuine reasoning, adaptability, implementation inconsistencies, prompt engineering complexity, evaluator diversity, and the overlooking of cultural and ideological norms in one comprehensive assessment. Our discussions emphasized the urgent need for standardized methodologies, regulatory certainties, and ethical guidelines in light of Artificial Intelligence (AI) advancements, including advocating for an evolution from static benchmarks to dynamic behavioral profiling to accurately capture LLMs' complex behaviors and potential risks. Our study highlighted the necessity for a paradigm shift in LLM evaluation methodologies, underlining the importance of collaborative efforts for the development of universally accepted benchmarks and the enhancement of AI systems' integration into society.",
    "source": "ieee",
    "year": 2024,
    "authors": [
      "Timothy R. Mcintosh",
      "Teo Sušnjak",
      "Tong Liu",
      "Paul A. Watters",
      "Malka N. Halgamuge"
    ],
    "keywords": [
      "artificial intelligence",
      "large language models",
      "LLM"
    ],
    "doi": "10.1109/TAI.2025.3569516",
    "paper_id": "068ff3def994d1424832e1f56ed72ef8245a42f0",
    "citation_count": 84
  },
  {
    "id": "article_35",
    "title": "Cardiovascular care with digital twin technology in the era of generative artificial intelligence.",
    "abstract": "Digital twins, which are in silico replications of an individual and its environment, have advanced clinical decision-making and prognostication in cardiovascular medicine. The technology enables personalized simulations of clinical scenarios, prediction of disease risk, and strategies for clinical trial augmentation. Current applications of cardiovascular digital twins have integrated multi-modal data into mechanistic and statistical models to build physiologically accurate cardiac replicas to enhance disease phenotyping, enrich diagnostic workflows, and optimize procedural planning. Digital twin technology is rapidly evolving in the setting of newly available data modalities and advances in generative artificial intelligence, enabling dynamic and comprehensive simulations unique to an individual. These twins fuse physiologic, environmental, and healthcare data into machine learning and generative models to build real-time patient predictions that can model interactions with the clinical environment to accelerate personalized patient care. This review summarizes digital twins in cardiovascular medicine and their potential future applications by incorporating new personalized data modalities. It examines the technical advances in deep learning and generative artificial intelligence that broaden the scope and predictive power of digital twins. Finally, it highlights the individual and societal challenges as well as ethical considerations that are essential to realizing the future vision of incorporating cardiology digital twins into personalized cardiovascular care.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "P. Thangaraj",
      "Sean H Benson",
      "E. Oikonomou",
      "F. Asselbergs",
      "R. Khera"
    ],
    "keywords": [
      "artificial intelligence",
      "machine learning",
      "deep learning",
      "generative models"
    ],
    "doi": "10.1093/eurheartj/ehae619",
    "paper_id": "5a84d9a03dd422de6a5c9e9cbbd0ea93dd1c4f56",
    "citation_count": 48
  },
  {
    "id": "article_36",
    "title": "Does Generative Artificial Intelligence Improve the Academic Achievement of College Students? A Meta-Analysis",
    "abstract": "The use of generative artificial intelligence (Gen-AI) to assist college students in their studies has become a trend. However, there is no academic consensus on whether Gen-AI can enhance the academic achievement of college students. Using a meta-analytic approach, this study aims to investigate the effectiveness of Gen-AI in improving the academic achievement of college students and to explore the effects of different moderating variables. A total of 28 articles (65 independent studies, 1909 participants) met the inclusion criteria for this study. The results showed that Gen-AI significantly improved college students’ academic achievement with a medium effect size (Hedges’s g = 0.533, 95% CI [0.408,0.659], p < .05). There were within-group differences in the three moderator variables, activity categories, sample size, and generated content, when the generated content was text (g = 0.554, p < .05), and sample size of 21–40 (g = 0.776, p < .05), the use of independent learning styles (g = 0.600, p < .05) had the most significant improvement in college student’s academic achievement. The intervention duration, the discipline types, and the assessment tools also had a moderate positive impact on college students’ academic achievement, but there were no significant within-group differences in any of the moderating variables. This study provides a theoretical basis and empirical evidence for the scientific application of Gen-AI and the development of educational technology policy.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Lihui Sun",
      "Liang Zhou"
    ],
    "keywords": [
      "artificial intelligence"
    ],
    "doi": "10.1177/07356331241277937",
    "paper_id": "d2095344b9d7a0fd8b5955630c356b19da523c22",
    "citation_count": 46
  },
  {
    "id": "article_37",
    "title": "Generative Artificial Intelligence in Higher Education: Evidence from an Analysis of Institutional Policies and Guidelines",
    "abstract": "The release of ChatGPT in November 2022 prompted a massive uptake of generative artificial intelligence (GenAI) across higher education institutions (HEIs). HEIs scrambled to respond to its use, especially by students, looking first to regulate it and then arguing for its productive integration within teaching and learning. In the year since the release, HEIs have increasingly provided policies and guidelines to direct GenAI. In this paper we examined documents produced by 116 US universities categorized as high research activity or R1 institutions to comprehensively understand GenAI related advice and guidance given to institutional stakeholders. Through an extensive analysis, we found the majority of universities (N=73, 63%) encourage the use of GenAI and many provide detailed guidance for its use in the classroom (N=48, 41%). More than half of all institutions provided sample syllabi (N=65, 56%) and half (N=58, 50%) provided sample GenAI curriculum and activities that would help instructors integrate and leverage GenAI in their classroom. Notably, most guidance for activities focused on writing, whereas code and STEM-related activities were mentioned half the time and vaguely even when they were (N=58, 50%). Finally, more than one half of institutions talked about the ethics of GenAI on a range of topics broadly, including Diversity, Equity and Inclusion (DEI) (N=60, 52%). Overall, based on our findings we caution that guidance for faculty can become burdensome as extensive revision of pedagogical approaches is often recommended in the policies.",
    "source": "arxiv",
    "year": 2024,
    "authors": [
      "Nora McDonald",
      "Aditya Johri",
      "Areej Ali",
      "Aayushi Hingle"
    ],
    "keywords": [
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.48550/arXiv.2402.01659",
    "paper_id": "b29abff861c9a5e3b99faa440a74337326bdde20",
    "citation_count": 47
  },
  {
    "id": "article_38",
    "title": "Impacts of Generative Artificial Intelligence in Higher Education: Research Trends and Students’ Perceptions",
    "abstract": "In this paper, the effects of the rapid advancement of generative artificial intelligence (Gen AI) in higher education (HE) are discussed. A mixed exploratory research approach was employed to understand these impacts, combining analysis of current research trends and students’ perceptions of the effects of Gen AI tools in academia. Through bibliometric analysis and systematic literature review, 64 publications (indexed in the SCOPUS and Web of Science databases) were examined, highlighting Gen AI’s disruptive effect on the pedagogical aspects of HE. The impacts identified by the literature were compared with the perceptions held by computer science students of two different HE institutions (HEIs) on the topic. An exploratory study was developed based on the application of a questionnaire to a group of 112 students. The results suggest that while Gen AI can enhance academic work and learning feedback, it requires appropriate pedagogical support to foster critical, ethical, and digital literacy competencies. Students demonstrate awareness of both the risks and benefits associated with Gen AI in academic settings. The research concludes that failing to recognize and effectively use Gen AI in HE impedes educational progress and the adequate preparation of citizens and workers to think and act in an AI-mediated world.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Sandra Saúde",
      "João-Paulo Barros",
      "Inês Almeida"
    ],
    "keywords": [
      "artificial intelligence"
    ],
    "doi": "10.3390/socsci13080410",
    "paper_id": "9c556e6aa0167fb3c3e8c9509b9fa085b4e443b2",
    "citation_count": 47
  },
  {
    "id": "article_39",
    "title": "The Societal Impacts of Generative Artificial Intelligence: A Balanced Perspective",
    "abstract": "The discourse surrounding the societal impacts of generative artificial intelligence (GAI), exemplified\nby technologies like ChatGPT, often oscillates between extremes: utopian visions of unprecedented\nproductivity and dystopian fears of humanity’s demise. This polarized perspective neglects the\nnuanced, pragmatic manifestation of GAI. In general, extreme views oversimplify the technology itself\nor its potential to address societal issues. The authors suggest a more balanced analysis, acknowledging\nthat GAI’s impacts will unfold dynamically over time as diverse implementations interact with human\nstakeholders and contextual factors. While Big Tech firms dominate GAI’s supply, its demand is\nexpected to evolve through experimentation and use cases. The authors argue that GAI’s societal impact\ndepends on identifiable contingencies, emphasizing three broad factors: the balance between\nautomation and augmentation, the congruence of physical and digital realities, and the retention of\nhuman bounded rationality. These contingencies represent trade-offs arising from GAI instantiations,\nshaped by technological advancements, stakeholder dynamics, and contextual factors, including\nsocietal responses and regulations. Predicting long-term societal effects remains challenging due to\nunforeseeable discontinuities in the technology’s trajectory. The authors anticipate a continuous\ninterplay between GAI initiatives, technological advances, learning experiences, and societal\nresponses, with outcomes depending on the above contingencies.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "R. Sabherwal",
      "Varun Grover"
    ],
    "keywords": [
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.17705/1jais.00860",
    "paper_id": "67756c32f468f21f0b3668ba20ed031e2c8fc9e5",
    "citation_count": 45
  },
  {
    "id": "article_40",
    "title": "Unlocking de novo antibody design with generative artificial intelligence",
    "abstract": "Generative AI has the potential to redefine the process of therapeutic antibody discovery. In this report, we describe and validate deep generative models for the de novo design of antibodies against human epidermal growth factor receptor (HER2) without additional optimization. The models enabled an efficient workflow that combined in silico design methods with high-throughput experimental techniques to rapidly identify binders from a library of ∼106 heavy chain complementarity-determining region (HCDR) variants. We demonstrated that the workflow achieves binding rates of 10.6% for HCDR3 and 1.8% for HCDR123 designs and is statistically superior to baselines. We further characterized 421 diverse binders using surface plasmon resonance (SPR), finding 71 with low nanomolar affinity similar to the therapeutic anti-HER2 antibody trastuzumab. A selected subset of 11 diverse high-affinity binders were functionally equivalent or superior to trastuzumab, with most demonstrating suitable developability features. We designed one binder with ∼3x higher cell-based potency compared to trastuzumab and another with improved cross-species reactivity1. Our generative AI approach unlocks an accelerated path to designing therapeutic antibodies against diverse targets.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Amir Shanehsazzadeh",
      "S. Bachas",
      "George Kasun",
      "J. Sutton",
      "A. Steiger"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence",
      "generative models"
    ],
    "doi": "10.1101/2023.01.08.523187",
    "paper_id": "adfcc00814fbb55a4b0c430c5c004bf7988734cb",
    "citation_count": 86
  },
  {
    "id": "article_41",
    "title": "A classification tool to foster self-regulated learning with generative artificial intelligence by applying self-determination theory: a case of ChatGPT",
    "abstract": "Generative AI such as ChatGPT provides an instant and individualized learning environment, and may have the potential to motivate student self-regulated learning (SRL), more effectively than other non-AI technologies. However, the impact of ChatGPT on student motivation, SRL, and needs satisfaction is unclear. Motivation and the SRL process can be explained using self-determination theory (SDT) and the three phases of forethought, performance, and self-reflection, respectively. Accordingly, a Delphi design was employed in this study to determine how ChatGPT-based learning activities satisfy students’ each SDT need, and foster each SRL phase from a teacher perspective. We involved 36 SDT school teachers with extensive expertise in technology enhanced learning to develop a classification tool for learning activities that affect student needs satisfaction and SRL phases using ChatGPT. We collaborated with the teachers in three rounds to investigate and identify the activities, and we revised labels, descriptions, and explanations. The major finding is that a classification tool for 20 learning activities using ChatGPT was developed. The tool suggests how ChatGPT better satisfy SDT-based needs, and fosters the three SRL phrases. This classification tool can assist researchers in replicating, implementing, and integrating successful ChatGPT in education research and development projects. The tool can inspire teachers to modify the activities using generative AI for their own teaching, and inform policymakers on how to develop guidelines for AI in education.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "T. Chiu"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.1007/s11423-024-10366-w",
    "paper_id": "d69953ae182aaa1925a56c5ffe8c8be14f7c6cc8",
    "citation_count": 81
  },
  {
    "id": "article_42",
    "title": "Application of generative artificial intelligence (GenAI) in language teaching and learning: A scoping literature review",
    "abstract": "This paper discusses Application of generative artificial intelligence (GenAI) in language teaching and learning: A scoping literature review. Published in Computers and Education Open. Citations: 170.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Locky Law"
    ],
    "keywords": [
      "artificial intelligence"
    ],
    "doi": "10.1016/j.caeo.2024.100174",
    "paper_id": "4ff15a48ea0d0e402ea089ccd5a36087b612198e",
    "citation_count": 170
  },
  {
    "id": "article_43",
    "title": "Higher Education’s Generative Artificial Intelligence Paradox: The Meaning of Chatbot Mania",
    "abstract": "Higher education is currently under a significant transformation due to the emergence of generative artificial intelligence (GenAI) technologies, the hype surrounding GenAI and the increasing influence of educational technology business groups over tertiary education. This commentary, prepared for the Special Issue of the Journal of University Teaching & Learning Practice (JUTLP) on “Enhancing student engagement using Artificial Intelligence (AI) and chatbots,” delves into the complex landscape of opportunities and threats that AI chatbots, including ChatGPT, introduce to the realm of higher education. We argue that while GenAI offers promise in enhancing pedagogy, research, administration, and student support, concerns around academic integrity, labour displacement, embedded biases, environmental sustainability, increased commercialisation, and regulatory gaps necessitate a critical approach. Our commentary advocates for the development of critical AI literacy among educators and students, emphasising the necessity to foster an environment of responsible innovation and informed use of AI. We posit that the successful integration of AI in higher education must be grounded in the principles of ethics, equity, and the prioritisation of educational aims and human values. By offering a critical and nuanced exploration of these issues, our commentary aims to contribute to the ongoing discourse on how higher education institutions can navigate the rise of GenAI, ensuring that technological advancements benefit all stakeholders while upholding core academic values.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Juergen Rudolph",
      "Fadhil Mohamed Mohamed Ismail",
      "Stefan Popenici"
    ],
    "keywords": [
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.53761/54fs5e77",
    "paper_id": "5821c044982322e2aebfbadbf319cdf7f6e576bf",
    "citation_count": 44
  },
  {
    "id": "article_44",
    "title": "A Comparative Analysis of Generative Artificial Intelligence Tools for Natural Language Processing",
    "abstract": "Generative artificial intelligence tools have recently attracted a great deal of attention. This is because of their huge advantages, which include ease of usage, quick generation of answers to requests, and the human-like intelligence they possess. This paper presents a vivid comparative analysis of the top 9 generative artificial intelligence (AI) tools, namely ChatGPT, Perplexity AI, YouChat, ChatSonic, Google's Bard, Microsoft Bing Assistant, HuggingChat, Jasper AI, and Quora's Poe, paying attention to the Pros and Cons each of the AI tools presents. This comparative analysis shows that the generative AI tools have several Pros that outweigh the Cons. Further, we explore the transformative impact of generative AI in Natural Language Processing (NLP), focusing on its integration with search engines, privacy concerns, and ethical implications. A comparative analysis categorizes generative AI tools based on popularity and evaluates challenges in development, including data limitations and computational costs. The study highlights ethical considerations such as technology misuse and regulatory challenges. Additionally, we delved into AI Planning techniques in NLP, covering classical planning, probabilistic planning, hierarchical planning, temporal planning, knowledge-driven planning, and neural planning models. These planning approaches are vital in achieving specific goals in NLP tasks. In conclusion, we provide a concise overview of the current state of generative AI, including its challenges, ethical considerations, and potential applications, contributing to the academic discourse on human-computer interaction.  ",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "A. Iorliam",
      "Joseph Abunimye Ingio"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence",
      "GPT",
      "natural language processing",
      "NLP"
    ],
    "doi": "10.62411/jcta.9447",
    "paper_id": "aaa971c619766f9445c223a22783dab303b7d526",
    "citation_count": 44
  },
  {
    "id": "article_45",
    "title": "Ensuring useful adoption of generative artificial intelligence in healthcare",
    "abstract": "OBJECTIVES\nThis article aims to examine how generative artificial intelligence (AI) can be adopted with the most value in health systems, in response to the Executive Order on AI.\n\n\nMATERIALS AND METHODS\nWe reviewed how technology has historically been deployed in healthcare, and evaluated recent examples of deployments of both traditional AI and generative AI (GenAI) with a lens on value.\n\n\nRESULTS\nTraditional AI and GenAI are different technologies in terms of their capability and modes of current deployment, which have implications on value in health systems.\n\n\nDISCUSSION\nTraditional AI when applied with a framework top-down can realize value in healthcare. GenAI in the short term when applied top-down has unclear value, but encouraging more bottom-up adoption has the potential to provide more benefit to health systems and patients.\n\n\nCONCLUSION\nGenAI in healthcare can provide the most value for patients when health systems adapt culturally to grow with this new technology and its adoption patterns.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Jenelle A. Jindal",
      "M. Lungren",
      "Nigam H. Shah"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence"
    ],
    "doi": "10.1093/jamia/ocae043",
    "paper_id": "a63b0864afb934b2b5ffd032e89fbb7c0d4932a3",
    "citation_count": 39
  },
  {
    "id": "article_46",
    "title": "Factors affecting generative artificial intelligence, such as ChatGPT, use in higher education: An application of technology acceptance model",
    "abstract": "The adoption of generative artificial intelligence (GAI) tools, such as ChatGPT, in higher education presents numerous opportunities and challenges. The use of GAI technologies in various fields, including education, has accelerated as technology develops. The widely used language model ChatGPT, developed by OpenAI, has become progressively more important, especially in the field of education. This study employs the technology acceptance model to investigate the factors influencing the employment of ChatGPT within the higher education sector of Pakistan. This study employed the PLS‐SEM method for probing data collected from 368 Pakistani university students. The findings indicate that ChatGPT trust positively mediates the affiliation between ChatGPT self‐efficacy, ChatGPT actual use, ChatGPT use for information and ChatGPT use for interaction. Further, ChatGPT usefulness and ChatGPT ease of use significantly moderate the association between ChatGPT self‐efficacy and ChatGPT trust. Educators must encourage students to use ChatGPT safely to preserve their critical thinking, problem‐solving abilities and creativity during assessments. This study contributes to understanding generative AI tools such as ChatGPT that are used in educational settings and provides insights for administrators and policymakers aiming to implement these technologies effectively.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Muhammad Farrukh Shahzad",
      "Shuo Xu",
      "Muhammad Asif"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.1002/berj.4084",
    "paper_id": "a13bbde142ea866156a8ae8b1801fb6179c9ffd2",
    "citation_count": 38
  },
  {
    "id": "article_47",
    "title": "Generative Artificial Intelligence Assisted Wireless Sensing: Human Flow Detection in Practical Communication Environments",
    "abstract": "Groundbreaking applications such as ChatGPT have heightened research interest in generative artificial intelligence (GAI). Essentially, GAI excels not only in content generation but also signal processing, offering support for wireless sensing. Hence, we introduce a novel GAI-assisted human flow detection system (G-HFD). Rigorously, G-HFD first uses the channel state information (CSI) to estimate the velocity and acceleration of propagation path length change of the human induced reflection (HIR). Then, given the strong inference ability of the diffusion model, we propose a unified weighted conditional diffusion model (UW-CDM) to denoise the estimation results, enabling detection of the number of targets. Next, we use the CSI obtained by a uniform linear array with wavelength spacing to estimate the HIR’s time of flight and direction of arrival (DoA). In this process, UW-CDM solves the problem of ambiguous DoA spectrum, ensuring accurate DoA estimation. Finally, through clustering, G-HFD determines the number of subflows and the number of targets in each subflow, i.e., the subflow size. The evaluation based on practical downlink communication signals shows G-HFD’s accuracy of subflow size detection can reach 91%. This validates its effectiveness and underscores the significant potential of GAI in the context of wireless sensing.",
    "source": "ieee",
    "year": 2024,
    "authors": [
      "Jiacheng Wang",
      "Hongyang Du",
      "Dusist Niyato",
      "Zehui Xiong",
      "Jiawen Kang"
    ],
    "keywords": [
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.1109/JSAC.2024.3414628",
    "paper_id": "209d51c3753fddfc5f5b7d158dadb9bc67ecb3e0",
    "citation_count": 40
  },
  {
    "id": "article_48",
    "title": "The ChatGPT Effect: Nursing Education and Generative Artificial Intelligence.",
    "abstract": "This paper discusses The ChatGPT Effect: Nursing Education and Generative Artificial Intelligence.. Published in The Journal of Nursery Education. Citations: 43.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "M. Topaz",
      "Laura-Maria Peltonen",
      "Martin Michalowski",
      "Gregor Stiglic",
      "C. Ronquillo"
    ],
    "keywords": [
      "artificial intelligence",
      "GPT"
    ],
    "doi": "10.3928/01484834-20240126-01",
    "paper_id": "5326f0b6882ee8c1043e718b007c3595858f48fe",
    "citation_count": 43
  },
  {
    "id": "article_49",
    "title": "Generative artificial intelligence in manufacturing: opportunities for actualizing Industry 5.0 sustainability goals",
    "abstract": "PurposeThis study offers practical insights into how generative artificial intelligence (AI) can enhance responsible manufacturing within the context of Industry 5.0. It explores how manufacturers can strategically maximize the potential benefits of generative AI through a synergistic approach.Design/methodology/approachThe study developed a strategic roadmap by employing a mixed qualitative-quantitative research method involving case studies, interviews and interpretive structural modeling (ISM). This roadmap visualizes and elucidates the mechanisms through which generative AI can contribute to advancing the sustainability goals of Industry 5.0.FindingsGenerative AI has demonstrated the capability to promote various sustainability objectives within Industry 5.0 through ten distinct functions. These multifaceted functions address multiple facets of manufacturing, ranging from providing data-driven production insights to enhancing the resilience of manufacturing operations.Practical implicationsWhile each identified generative AI function independently contributes to responsible manufacturing under Industry 5.0, leveraging them individually is a viable strategy. However, they synergistically enhance each other when systematically employed in a specific order. Manufacturers are advised to strategically leverage these functions, drawing on their complementarities to maximize their benefits.Originality/valueThis study pioneers by providing early practical insights into how generative AI enhances the sustainability performance of manufacturers within the Industry 5.0 framework. The proposed strategic roadmap suggests prioritization orders, guiding manufacturers in decision-making processes regarding where and for what purpose to integrate generative AI.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Morteza Ghobakhloo",
      "Masood Fathi",
      "Mohammad Iranmanesh",
      "Mantas Vilkas",
      "Andrius Grybauskas"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence"
    ],
    "doi": "10.1108/jmtm-12-2023-0530",
    "paper_id": "2ea12f6beb2d504b985503e945526a85251ed3af",
    "citation_count": 38
  },
  {
    "id": "article_50",
    "title": "Generative Artificial Intelligence and Evaluating Strategic Decisions",
    "abstract": "Strategic decisions are uncertain and often irreversible. Hence, predicting the value of alternatives is important for strategic decision making. We investigate the use of generative artificial intelligence (AI) in evaluating strategic alternatives using business models generated by AI (study 1) or submitted to a competition (study 2). Each study uses a sample of 60 business models and examines agreement in business model rankings made by large language models (LLMs) and those by human experts. We consider multiple LLMs, assumed LLM roles, and prompts. We find that generative AI often produces evaluations that are inconsistent and biased. However, when aggregating evaluations, AI rankings tend to resemble those of human experts. This study highlights the value of generative AI in strategic decision making by providing predictions.Managers are seeking to create value by integrating generative AI into their organizations. We show how managers can use generative AI to help evaluate strategic decisions. Generative AI's single evaluations are often inconsistent or biased. However, if managers aggregate many evaluations across LLMs, prompts, or roles, the results show that the resulting evaluations tend to resemble those of human experts. This approach allows managers to obtain insight on strategic decisions across a variety of domains with relatively low investments in time or resources, which can be combined with human inputs.",
    "source": "semantic_scholar",
    "year": 2024,
    "authors": [
      "Anil R. Doshi",
      "J. J. Bell",
      "Emil Mirzayev",
      "Bart S. Vanneste"
    ],
    "keywords": [
      "generative AI",
      "artificial intelligence",
      "large language models",
      "LLM"
    ],
    "doi": "10.2139/ssrn.4714776",
    "paper_id": "1b43632036f7e1f45a4759849f2924478eccc81e",
    "citation_count": 43
  }
]